{
  
    
        "post0": {
            "title": "Surface Defect Segmentation",
            "content": "In this notebook we use the segmentation models library built in PyTorch to build image segmentation models for the Magnetic tile defect dataset. This dataset is interesting because it is highly imbalanced, with less than 1% of pixels corresponding to the target class. Using the segmentation models library we can try several different loss functions, including binary cross entropy, focal losss, and Tversky loss to see their performance. . Aditionally, following an example in the segmentation models library, we&#39;ll use PyTorch Lightning to further simplify the training process in PyTorch and MLflow to log hyperparameters and metrics. . This code is built with the help of Detection of Surface Defects in Magnetic Tile Images by Dr. Mitra P. Danesh. . #!pip install torch torchvision !pip install -U git+https://github.com/qubvel/segmentation_models.pytorch !pip install pytorch-lightning !pip install mlflow . Collecting torch Downloading torch-1.12.0-cp39-cp39-manylinux1_x86_64.whl (776.3 MB) |████████████████████████████████| 776.3 MB 2.1 kB/s | 426.3 MB 9.2 MB/s eta 0:00:39 |███████████████████▍ | 470.4 MB 235 kB/s eta 0:21:42 ��██████████████████▍ | 470.5 MB 235 kB/s eta 0:21:42 ��███ | 607.5 MB 6.6 MB/s eta 0:00:26 MB 8.6 MB/s eta 0:00:01 MB 316 kB/s eta 0:00:01 Collecting torchvision Downloading torchvision-0.13.0-cp39-cp39-manylinux1_x86_64.whl (19.1 MB) |████████████████████████████████| 19.1 MB 865 kB/s Requirement already satisfied: typing-extensions in /opt/conda/lib/python3.9/site-packages (from torch) (3.7.4.3) Requirement already satisfied: numpy in /opt/conda/lib/python3.9/site-packages (from torchvision) (1.19.5) Requirement already satisfied: pillow!=8.3.*,&gt;=5.3.0 in /opt/conda/lib/python3.9/site-packages (from torchvision) (8.4.0) Requirement already satisfied: requests in /opt/conda/lib/python3.9/site-packages (from torchvision) (2.27.1) Requirement already satisfied: charset-normalizer~=2.0.0 in /opt/conda/lib/python3.9/site-packages (from requests-&gt;torchvision) (2.0.10) Requirement already satisfied: certifi&gt;=2017.4.17 in /opt/conda/lib/python3.9/site-packages (from requests-&gt;torchvision) (2021.10.8) Requirement already satisfied: idna&lt;4,&gt;=2.5 in /opt/conda/lib/python3.9/site-packages (from requests-&gt;torchvision) (3.1) Requirement already satisfied: urllib3&lt;1.27,&gt;=1.21.1 in /opt/conda/lib/python3.9/site-packages (from requests-&gt;torchvision) (1.26.8) Installing collected packages: torch, torchvision Successfully installed torch-1.12.0 torchvision-0.13.0 Collecting git+https://github.com/qubvel/segmentation_models.pytorch Cloning https://github.com/qubvel/segmentation_models.pytorch to /tmp/pip-req-build-ba97ov95 Running command git clone --filter=blob:none -q https://github.com/qubvel/segmentation_models.pytorch /tmp/pip-req-build-ba97ov95 Resolved https://github.com/qubvel/segmentation_models.pytorch to commit 740dab561ccf54a9ae4bb5bda3b8b18df3790025 Installing build dependencies ... done Getting requirements to build wheel ... done Preparing metadata (pyproject.toml) ... done Requirement already satisfied: tqdm in /opt/conda/lib/python3.9/site-packages (from segmentation-models-pytorch==0.3.0.dev0) (4.62.3) Collecting pretrainedmodels==0.7.4 Downloading pretrainedmodels-0.7.4.tar.gz (58 kB) |████████████████████████████████| 58 kB 3.3 MB/s Preparing metadata (setup.py) ... done Requirement already satisfied: pillow in /opt/conda/lib/python3.9/site-packages (from segmentation-models-pytorch==0.3.0.dev0) (8.4.0) Collecting efficientnet-pytorch==0.6.3 Downloading efficientnet_pytorch-0.6.3.tar.gz (16 kB) Preparing metadata (setup.py) ... done Requirement already satisfied: torchvision&gt;=0.5.0 in /opt/conda/lib/python3.9/site-packages (from segmentation-models-pytorch==0.3.0.dev0) (0.13.0) Collecting timm==0.4.12 Downloading timm-0.4.12-py3-none-any.whl (376 kB) |████████████████████████████████| 376 kB 6.6 MB/s Requirement already satisfied: torch in /opt/conda/lib/python3.9/site-packages (from efficientnet-pytorch==0.6.3-&gt;segmentation-models-pytorch==0.3.0.dev0) (1.12.0) Collecting munch Downloading munch-2.5.0-py2.py3-none-any.whl (10 kB) Requirement already satisfied: numpy in /opt/conda/lib/python3.9/site-packages (from torchvision&gt;=0.5.0-&gt;segmentation-models-pytorch==0.3.0.dev0) (1.19.5) Requirement already satisfied: requests in /opt/conda/lib/python3.9/site-packages (from torchvision&gt;=0.5.0-&gt;segmentation-models-pytorch==0.3.0.dev0) (2.27.1) Requirement already satisfied: typing-extensions in /opt/conda/lib/python3.9/site-packages (from torchvision&gt;=0.5.0-&gt;segmentation-models-pytorch==0.3.0.dev0) (3.7.4.3) Requirement already satisfied: six in /opt/conda/lib/python3.9/site-packages (from munch-&gt;pretrainedmodels==0.7.4-&gt;segmentation-models-pytorch==0.3.0.dev0) (1.15.0) Requirement already satisfied: charset-normalizer~=2.0.0 in /opt/conda/lib/python3.9/site-packages (from requests-&gt;torchvision&gt;=0.5.0-&gt;segmentation-models-pytorch==0.3.0.dev0) (2.0.10) Requirement already satisfied: certifi&gt;=2017.4.17 in /opt/conda/lib/python3.9/site-packages (from requests-&gt;torchvision&gt;=0.5.0-&gt;segmentation-models-pytorch==0.3.0.dev0) (2021.10.8) Requirement already satisfied: urllib3&lt;1.27,&gt;=1.21.1 in /opt/conda/lib/python3.9/site-packages (from requests-&gt;torchvision&gt;=0.5.0-&gt;segmentation-models-pytorch==0.3.0.dev0) (1.26.8) Requirement already satisfied: idna&lt;4,&gt;=2.5 in /opt/conda/lib/python3.9/site-packages (from requests-&gt;torchvision&gt;=0.5.0-&gt;segmentation-models-pytorch==0.3.0.dev0) (3.1) Building wheels for collected packages: segmentation-models-pytorch, efficientnet-pytorch, pretrainedmodels Building wheel for segmentation-models-pytorch (pyproject.toml) ... done Created wheel for segmentation-models-pytorch: filename=segmentation_models_pytorch-0.3.0.dev0-py3-none-any.whl size=97989 sha256=6a83fe356cdef1ec3e8122f481cc929e2c2b8a4fb7d34a29f2cc946ff9642b59 Stored in directory: /tmp/pip-ephem-wheel-cache-xw45cnat/wheels/18/f6/12/bdbad33e766c5fddfa996bfb2545d31ca070438d37e5b76408 Building wheel for efficientnet-pytorch (setup.py) ... done Created wheel for efficientnet-pytorch: filename=efficientnet_pytorch-0.6.3-py3-none-any.whl size=12421 sha256=2f18917afcad49b5cba9fbfd933b2b521984185668657c1f2a7ac7e3376fb137 Stored in directory: /home/jovyan/.cache/pip/wheels/70/f8/49/20f330df3f946fed839df657dd2156c929d6d7b5f774d9650e Building wheel for pretrainedmodels (setup.py) ... done Created wheel for pretrainedmodels: filename=pretrainedmodels-0.7.4-py3-none-any.whl size=60965 sha256=c5189a41cbaee763f23109c04e67d67b0848d41b32b80f4a64cd85bcb04e696a Stored in directory: /home/jovyan/.cache/pip/wheels/d1/3b/4e/2f3015f1ab76f34be28e04c4bcee27e8cabfa70d2eadf8bc3b Successfully built segmentation-models-pytorch efficientnet-pytorch pretrainedmodels Installing collected packages: munch, timm, pretrainedmodels, efficientnet-pytorch, segmentation-models-pytorch Successfully installed efficientnet-pytorch-0.6.3 munch-2.5.0 pretrainedmodels-0.7.4 segmentation-models-pytorch-0.3.0.dev0 timm-0.4.12 Collecting pytorch-lightning Downloading pytorch_lightning-1.6.4-py3-none-any.whl (585 kB) |████████████████████████████████| 585 kB 3.8 MB/s Requirement already satisfied: packaging&gt;=17.0 in /opt/conda/lib/python3.9/site-packages (from pytorch-lightning) (21.3) Requirement already satisfied: tqdm&gt;=4.57.0 in /opt/conda/lib/python3.9/site-packages (from pytorch-lightning) (4.62.3) Requirement already satisfied: torch&gt;=1.8.* in /opt/conda/lib/python3.9/site-packages (from pytorch-lightning) (1.12.0) Collecting torchmetrics&gt;=0.4.1 Downloading torchmetrics-0.9.2-py3-none-any.whl (419 kB) |████████████████████████████████| 419 kB 6.2 MB/s Requirement already satisfied: tensorboard&gt;=2.2.0 in /opt/conda/lib/python3.9/site-packages (from pytorch-lightning) (2.6.0) Requirement already satisfied: numpy&gt;=1.17.2 in /opt/conda/lib/python3.9/site-packages (from pytorch-lightning) (1.19.5) Collecting typing-extensions&gt;=4.0.0 Downloading typing_extensions-4.2.0-py3-none-any.whl (24 kB) Requirement already satisfied: protobuf&lt;=3.20.1 in /opt/conda/lib/python3.9/site-packages (from pytorch-lightning) (3.18.1) Requirement already satisfied: PyYAML&gt;=5.4 in /opt/conda/lib/python3.9/site-packages (from pytorch-lightning) (6.0) Collecting pyDeprecate&gt;=0.3.1 Downloading pyDeprecate-0.3.2-py3-none-any.whl (10 kB) Requirement already satisfied: fsspec[http]!=2021.06.0,&gt;=2021.05.0 in /opt/conda/lib/python3.9/site-packages (from pytorch-lightning) (2022.1.0) Requirement already satisfied: requests in /opt/conda/lib/python3.9/site-packages (from fsspec[http]!=2021.06.0,&gt;=2021.05.0-&gt;pytorch-lightning) (2.27.1) Requirement already satisfied: aiohttp in /opt/conda/lib/python3.9/site-packages (from fsspec[http]!=2021.06.0,&gt;=2021.05.0-&gt;pytorch-lightning) (3.8.1) Requirement already satisfied: pyparsing!=3.0.5,&gt;=2.0.2 in /opt/conda/lib/python3.9/site-packages (from packaging&gt;=17.0-&gt;pytorch-lightning) (3.0.6) Requirement already satisfied: setuptools&gt;=41.0.0 in /opt/conda/lib/python3.9/site-packages (from tensorboard&gt;=2.2.0-&gt;pytorch-lightning) (60.5.0) Requirement already satisfied: tensorboard-plugin-wit&gt;=1.6.0 in /opt/conda/lib/python3.9/site-packages (from tensorboard&gt;=2.2.0-&gt;pytorch-lightning) (1.8.1) Requirement already satisfied: google-auth-oauthlib&lt;0.5,&gt;=0.4.1 in /opt/conda/lib/python3.9/site-packages (from tensorboard&gt;=2.2.0-&gt;pytorch-lightning) (0.4.6) Requirement already satisfied: grpcio&gt;=1.24.3 in /opt/conda/lib/python3.9/site-packages (from tensorboard&gt;=2.2.0-&gt;pytorch-lightning) (1.41.1) Requirement already satisfied: google-auth&lt;2,&gt;=1.6.3 in /opt/conda/lib/python3.9/site-packages (from tensorboard&gt;=2.2.0-&gt;pytorch-lightning) (1.35.0) Requirement already satisfied: absl-py&gt;=0.4 in /opt/conda/lib/python3.9/site-packages (from tensorboard&gt;=2.2.0-&gt;pytorch-lightning) (0.15.0) Requirement already satisfied: tensorboard-data-server&lt;0.7.0,&gt;=0.6.0 in /opt/conda/lib/python3.9/site-packages (from tensorboard&gt;=2.2.0-&gt;pytorch-lightning) (0.6.0) Requirement already satisfied: werkzeug&gt;=0.11.15 in /opt/conda/lib/python3.9/site-packages (from tensorboard&gt;=2.2.0-&gt;pytorch-lightning) (2.0.1) Requirement already satisfied: wheel&gt;=0.26 in /opt/conda/lib/python3.9/site-packages (from tensorboard&gt;=2.2.0-&gt;pytorch-lightning) (0.37.1) Requirement already satisfied: markdown&gt;=2.6.8 in /opt/conda/lib/python3.9/site-packages (from tensorboard&gt;=2.2.0-&gt;pytorch-lightning) (3.3.6) Requirement already satisfied: six in /opt/conda/lib/python3.9/site-packages (from absl-py&gt;=0.4-&gt;tensorboard&gt;=2.2.0-&gt;pytorch-lightning) (1.15.0) Requirement already satisfied: rsa&lt;5,&gt;=3.1.4 in /opt/conda/lib/python3.9/site-packages (from google-auth&lt;2,&gt;=1.6.3-&gt;tensorboard&gt;=2.2.0-&gt;pytorch-lightning) (4.8) Requirement already satisfied: pyasn1-modules&gt;=0.2.1 in /opt/conda/lib/python3.9/site-packages (from google-auth&lt;2,&gt;=1.6.3-&gt;tensorboard&gt;=2.2.0-&gt;pytorch-lightning) (0.2.7) Requirement already satisfied: cachetools&lt;5.0,&gt;=2.0.0 in /opt/conda/lib/python3.9/site-packages (from google-auth&lt;2,&gt;=1.6.3-&gt;tensorboard&gt;=2.2.0-&gt;pytorch-lightning) (4.2.4) Requirement already satisfied: requests-oauthlib&gt;=0.7.0 in /opt/conda/lib/python3.9/site-packages (from google-auth-oauthlib&lt;0.5,&gt;=0.4.1-&gt;tensorboard&gt;=2.2.0-&gt;pytorch-lightning) (1.3.0) Requirement already satisfied: importlib-metadata&gt;=4.4 in /opt/conda/lib/python3.9/site-packages (from markdown&gt;=2.6.8-&gt;tensorboard&gt;=2.2.0-&gt;pytorch-lightning) (4.10.0) Requirement already satisfied: charset-normalizer~=2.0.0 in /opt/conda/lib/python3.9/site-packages (from requests-&gt;fsspec[http]!=2021.06.0,&gt;=2021.05.0-&gt;pytorch-lightning) (2.0.10) Requirement already satisfied: idna&lt;4,&gt;=2.5 in /opt/conda/lib/python3.9/site-packages (from requests-&gt;fsspec[http]!=2021.06.0,&gt;=2021.05.0-&gt;pytorch-lightning) (3.1) Requirement already satisfied: urllib3&lt;1.27,&gt;=1.21.1 in /opt/conda/lib/python3.9/site-packages (from requests-&gt;fsspec[http]!=2021.06.0,&gt;=2021.05.0-&gt;pytorch-lightning) (1.26.8) Requirement already satisfied: certifi&gt;=2017.4.17 in /opt/conda/lib/python3.9/site-packages (from requests-&gt;fsspec[http]!=2021.06.0,&gt;=2021.05.0-&gt;pytorch-lightning) (2021.10.8) Requirement already satisfied: multidict&lt;7.0,&gt;=4.5 in /opt/conda/lib/python3.9/site-packages (from aiohttp-&gt;fsspec[http]!=2021.06.0,&gt;=2021.05.0-&gt;pytorch-lightning) (5.2.0) Requirement already satisfied: frozenlist&gt;=1.1.1 in /opt/conda/lib/python3.9/site-packages (from aiohttp-&gt;fsspec[http]!=2021.06.0,&gt;=2021.05.0-&gt;pytorch-lightning) (1.2.0) Requirement already satisfied: async-timeout&lt;5.0,&gt;=4.0.0a3 in /opt/conda/lib/python3.9/site-packages (from aiohttp-&gt;fsspec[http]!=2021.06.0,&gt;=2021.05.0-&gt;pytorch-lightning) (4.0.2) Requirement already satisfied: attrs&gt;=17.3.0 in /opt/conda/lib/python3.9/site-packages (from aiohttp-&gt;fsspec[http]!=2021.06.0,&gt;=2021.05.0-&gt;pytorch-lightning) (21.4.0) Requirement already satisfied: yarl&lt;2.0,&gt;=1.0 in /opt/conda/lib/python3.9/site-packages (from aiohttp-&gt;fsspec[http]!=2021.06.0,&gt;=2021.05.0-&gt;pytorch-lightning) (1.7.2) Requirement already satisfied: aiosignal&gt;=1.1.2 in /opt/conda/lib/python3.9/site-packages (from aiohttp-&gt;fsspec[http]!=2021.06.0,&gt;=2021.05.0-&gt;pytorch-lightning) (1.2.0) Requirement already satisfied: zipp&gt;=0.5 in /opt/conda/lib/python3.9/site-packages (from importlib-metadata&gt;=4.4-&gt;markdown&gt;=2.6.8-&gt;tensorboard&gt;=2.2.0-&gt;pytorch-lightning) (3.7.0) Requirement already satisfied: pyasn1&lt;0.5.0,&gt;=0.4.6 in /opt/conda/lib/python3.9/site-packages (from pyasn1-modules&gt;=0.2.1-&gt;google-auth&lt;2,&gt;=1.6.3-&gt;tensorboard&gt;=2.2.0-&gt;pytorch-lightning) (0.4.8) Requirement already satisfied: oauthlib&gt;=3.0.0 in /opt/conda/lib/python3.9/site-packages (from requests-oauthlib&gt;=0.7.0-&gt;google-auth-oauthlib&lt;0.5,&gt;=0.4.1-&gt;tensorboard&gt;=2.2.0-&gt;pytorch-lightning) (3.1.1) Installing collected packages: typing-extensions, torchmetrics, pyDeprecate, pytorch-lightning Attempting uninstall: typing-extensions Found existing installation: typing-extensions 3.7.4.3 Uninstalling typing-extensions-3.7.4.3: Successfully uninstalled typing-extensions-3.7.4.3 ERROR: pip&#39;s dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts. tensorflow 2.6.2 requires typing-extensions~=3.7.4, but you have typing-extensions 4.2.0 which is incompatible. Successfully installed pyDeprecate-0.3.2 pytorch-lightning-1.6.4 torchmetrics-0.9.2 typing-extensions-4.2.0 Collecting mlflow Downloading mlflow-1.27.0-py3-none-any.whl (17.9 MB) |████████████████████████████████| 17.9 MB 10.7 MB/s Collecting Flask Downloading Flask-2.1.2-py3-none-any.whl (95 kB) |████████████████████████████████| 95 kB 3.1 MB/s Requirement already satisfied: requests&gt;=2.17.3 in /opt/conda/lib/python3.9/site-packages (from mlflow) (2.27.1) Requirement already satisfied: protobuf&gt;=3.12.0 in /opt/conda/lib/python3.9/site-packages (from mlflow) (3.18.1) Requirement already satisfied: entrypoints in /opt/conda/lib/python3.9/site-packages (from mlflow) (0.3) Collecting docker&gt;=4.0.0 Downloading docker-5.0.3-py2.py3-none-any.whl (146 kB) |████████████████████████████████| 146 kB 11.8 MB/s Collecting sqlparse&gt;=0.3.1 Downloading sqlparse-0.4.2-py3-none-any.whl (42 kB) |████████████████████████████████| 42 kB 798 kB/s Collecting querystring-parser Downloading querystring_parser-1.2.4-py2.py3-none-any.whl (7.9 kB) Requirement already satisfied: sqlalchemy&gt;=1.4.0 in /opt/conda/lib/python3.9/site-packages (from mlflow) (1.4.29) Requirement already satisfied: packaging in /opt/conda/lib/python3.9/site-packages (from mlflow) (21.3) Collecting gunicorn Downloading gunicorn-20.1.0-py3-none-any.whl (79 kB) |████████████████████████████████| 79 kB 5.0 MB/s Collecting databricks-cli&gt;=0.8.7 Downloading databricks-cli-0.17.0.tar.gz (81 kB) |████████████████████████████████| 81 kB 7.4 MB/s Preparing metadata (setup.py) ... done Requirement already satisfied: pytz in /opt/conda/lib/python3.9/site-packages (from mlflow) (2021.3) Requirement already satisfied: cloudpickle in /opt/conda/lib/python3.9/site-packages (from mlflow) (2.0.0) Requirement already satisfied: pyyaml&gt;=5.1 in /opt/conda/lib/python3.9/site-packages (from mlflow) (6.0) Requirement already satisfied: importlib-metadata!=4.7.0,&gt;=3.7.0 in /opt/conda/lib/python3.9/site-packages (from mlflow) (4.10.0) Collecting prometheus-flask-exporter Downloading prometheus_flask_exporter-0.20.2-py3-none-any.whl (18 kB) Collecting gitpython&gt;=2.1.0 Downloading GitPython-3.1.27-py3-none-any.whl (181 kB) |████████████████████████████████| 181 kB 10.0 MB/s Requirement already satisfied: alembic in /opt/conda/lib/python3.9/site-packages (from mlflow) (1.7.5) Requirement already satisfied: scipy in /opt/conda/lib/python3.9/site-packages (from mlflow) (1.7.3) Requirement already satisfied: numpy in /opt/conda/lib/python3.9/site-packages (from mlflow) (1.19.5) Requirement already satisfied: click&gt;=7.0 in /opt/conda/lib/python3.9/site-packages (from mlflow) (8.0.3) Requirement already satisfied: pandas in /opt/conda/lib/python3.9/site-packages (from mlflow) (1.3.5) Requirement already satisfied: pyjwt&gt;=1.7.0 in /opt/conda/lib/python3.9/site-packages (from databricks-cli&gt;=0.8.7-&gt;mlflow) (2.3.0) Requirement already satisfied: oauthlib&gt;=3.1.0 in /opt/conda/lib/python3.9/site-packages (from databricks-cli&gt;=0.8.7-&gt;mlflow) (3.1.1) Collecting tabulate&gt;=0.7.7 Downloading tabulate-0.8.10-py3-none-any.whl (29 kB) Requirement already satisfied: six&gt;=1.10.0 in /opt/conda/lib/python3.9/site-packages (from databricks-cli&gt;=0.8.7-&gt;mlflow) (1.15.0) Requirement already satisfied: websocket-client&gt;=0.32.0 in /opt/conda/lib/python3.9/site-packages (from docker&gt;=4.0.0-&gt;mlflow) (1.2.3) Collecting gitdb&lt;5,&gt;=4.0.1 Downloading gitdb-4.0.9-py3-none-any.whl (63 kB) |████████████████████████████████| 63 kB 1.9 MB/s Requirement already satisfied: zipp&gt;=0.5 in /opt/conda/lib/python3.9/site-packages (from importlib-metadata!=4.7.0,&gt;=3.7.0-&gt;mlflow) (3.7.0) Requirement already satisfied: charset-normalizer~=2.0.0 in /opt/conda/lib/python3.9/site-packages (from requests&gt;=2.17.3-&gt;mlflow) (2.0.10) Requirement already satisfied: idna&lt;4,&gt;=2.5 in /opt/conda/lib/python3.9/site-packages (from requests&gt;=2.17.3-&gt;mlflow) (3.1) Requirement already satisfied: certifi&gt;=2017.4.17 in /opt/conda/lib/python3.9/site-packages (from requests&gt;=2.17.3-&gt;mlflow) (2021.10.8) Requirement already satisfied: urllib3&lt;1.27,&gt;=1.21.1 in /opt/conda/lib/python3.9/site-packages (from requests&gt;=2.17.3-&gt;mlflow) (1.26.8) Requirement already satisfied: greenlet!=0.4.17 in /opt/conda/lib/python3.9/site-packages (from sqlalchemy&gt;=1.4.0-&gt;mlflow) (1.1.2) Requirement already satisfied: Mako in /opt/conda/lib/python3.9/site-packages (from alembic-&gt;mlflow) (1.1.6) Requirement already satisfied: Werkzeug&gt;=2.0 in /opt/conda/lib/python3.9/site-packages (from Flask-&gt;mlflow) (2.0.1) Collecting itsdangerous&gt;=2.0 Downloading itsdangerous-2.1.2-py3-none-any.whl (15 kB) Requirement already satisfied: Jinja2&gt;=3.0 in /opt/conda/lib/python3.9/site-packages (from Flask-&gt;mlflow) (3.0.3) Requirement already satisfied: setuptools&gt;=3.0 in /opt/conda/lib/python3.9/site-packages (from gunicorn-&gt;mlflow) (60.5.0) Requirement already satisfied: pyparsing!=3.0.5,&gt;=2.0.2 in /opt/conda/lib/python3.9/site-packages (from packaging-&gt;mlflow) (3.0.6) Requirement already satisfied: python-dateutil&gt;=2.7.3 in /opt/conda/lib/python3.9/site-packages (from pandas-&gt;mlflow) (2.8.2) Requirement already satisfied: prometheus-client in /opt/conda/lib/python3.9/site-packages (from prometheus-flask-exporter-&gt;mlflow) (0.12.0) Collecting smmap&lt;6,&gt;=3.0.1 Downloading smmap-5.0.0-py3-none-any.whl (24 kB) Requirement already satisfied: MarkupSafe&gt;=2.0 in /opt/conda/lib/python3.9/site-packages (from Jinja2&gt;=3.0-&gt;Flask-&gt;mlflow) (2.0.1) Building wheels for collected packages: databricks-cli Building wheel for databricks-cli (setup.py) ... done Created wheel for databricks-cli: filename=databricks_cli-0.17.0-py3-none-any.whl size=141960 sha256=af13856c6d0a21dde1b8a0f8573bd6969c313c1425c065d9b919ba8f270fd1de Stored in directory: /home/jovyan/.cache/pip/wheels/d5/b6/71/c3052c82e4a88dc658dd2616b944e130c1d0ff3f77e8f02df7 Successfully built databricks-cli Installing collected packages: smmap, itsdangerous, tabulate, gitdb, Flask, sqlparse, querystring-parser, prometheus-flask-exporter, gunicorn, gitpython, docker, databricks-cli, mlflow Successfully installed Flask-2.1.2 databricks-cli-0.17.0 docker-5.0.3 gitdb-4.0.9 gitpython-3.1.27 gunicorn-20.1.0 itsdangerous-2.1.2 mlflow-1.27.0 prometheus-flask-exporter-0.20.2 querystring-parser-1.2.4 smmap-5.0.0 sqlparse-0.4.2 tabulate-0.8.10 . import os import random import torch import numpy as np import segmentation_models_pytorch as smp import pytorch_lightning as pl from torch.utils.data import DataLoader from torch.utils.data import Dataset as BaseDataset from pytorch_lightning import Trainer from pytorch_lightning.loggers import MLFlowLogger # set the random seeds for reproducibility random.seed(42) torch.manual_seed(0) np.random.seed(0) . Loading data . from torch.utils.data import random_split import torchvision.transforms as transforms from torch.utils.data import Dataset from PIL import Image from glob import glob . First download the data locally. . %%capture !wget -O data.zip https://github.com/abin24/Magnetic-tile-defect-datasets./archive/master.zip !unzip data.zip !mv Magnetic-tile-defect-datasets.-master data . classes =[&#39;Blowhole&#39;, &#39;Crack&#39;,&#39;Free&#39;] # classes/labels image_paths = [] for c in classes: # retreive image file paths recursively images_found = glob(&#39;data/MT_&#39; + c + &#39;/Imgs/*.jpg&#39;,recursive=True) if c== &#39;Free&#39;: # undersample the free class. image_paths.extend( images_found[:80] ) else: image_paths.extend( images_found ) random.shuffle(image_paths) . len(image_paths) . 252 . Dataset . Writing helper class for data extraction, tranformation and preprocessing https://pytorch.org/docs/stable/data. Also see the binary segmentation intro in the segmentation models library for more details on designing the Dataset class. . import torchvision.transforms.functional as TF import random class SurfaceDefectDetectionDataset(Dataset): def __init__(self, image_path_list, use_transform=False): super().__init__() self.image_path_list = image_path_list self.use_transform = use_transform def transform(self, image, target): if random.random() &lt; 0.5: image = TF.hflip(image) target = TF.hflip(target) if random.random() &lt; 0.5: image = TF.vflip(image) target = TF.vflip(target) angle = random.choice([0, -90, 90, 180]) image, target = TF.rotate(image, angle), TF.rotate(target, angle) return image, target def __len__(self): return len(self.image_path_list) def __getitem__(self, idx): # Open the image file which is in jpg image = Image.open(self.image_path_list[idx]) # The mask is in png. # Use the image path, and change its extension to png to get the mask&#39;s path. mask = Image.open(os.path.splitext(self.image_path_list[idx])[0]+&#39;.png&#39;) # resize the images. image, mask = TF.resize(image, (320,320)), TF.resize(mask, (320,320)) # Perform augmentation if required. if self.use_transform: image, mask = self.transform(image, mask) # Transform the image and mask PILs to torch tensors. image, mask = TF.to_tensor(image), TF.to_tensor(mask) # Threshold mask, threshold limit is 0.5 mask = (mask &gt;= 0.5)*(1.0) #return the image and mask pair tensors return image, mask . split_len = int(0.8*len(image_paths)) train_dataset = SurfaceDefectDetectionDataset(image_paths[:split_len], use_transform = True) test_dataset = SurfaceDefectDetectionDataset(image_paths[split_len:], use_transform = False) . train_dataset, val_dataset = random_split(train_dataset, [int(split_len*0.9), split_len - int(split_len*0.9)], generator=torch.Generator().manual_seed(1)) . print(&#39;Length of train dataset: &#39;, len(train_dataset)) print(&#39;Length of validation dataset: &#39;, len(val_dataset)) print(&#39;Length of test dataset: &#39;, len(test_dataset)) . Length of train dataset: 180 Length of validation dataset: 21 Length of test dataset: 51 . Let&#39;s take a look at the dataset . import matplotlib.pyplot as plt import random sample_img, sample_msk = train_dataset[random.choice(range(len(train_dataset)))] plt.subplot(1,2,1) plt.title(&quot;Sample from trainining set&quot;) plt.axis(&quot;off&quot;) plt.imshow(sample_img.squeeze(), cmap=&#39;gray&#39;) plt.subplot(1,2,2) plt.axis(&quot;off&quot;) plt.imshow(sample_msk.squeeze(), cmap=&#39;gray&#39;) plt.show() sample_img, sample_msk = val_dataset[random.choice(range(len(val_dataset)))] plt.subplot(1,2,1) plt.title(&quot;Sample from validation set&quot;) plt.axis(&quot;off&quot;) plt.imshow(sample_img.squeeze(), cmap=&#39;gray&#39;) plt.subplot(1,2,2) plt.axis(&quot;off&quot;) plt.imshow(sample_msk.squeeze(), cmap=&#39;gray&#39;) plt.show() sample_img, sample_msk = test_dataset[random.choice(range(len(test_dataset)))] plt.subplot(1,2,1) plt.title(&quot;Sample from test set&quot;) plt.axis(&quot;off&quot;) plt.imshow(sample_img.squeeze(), cmap=&#39;gray&#39;) plt.subplot(1,2,2) plt.axis(&quot;off&quot;) plt.imshow(sample_msk.squeeze(), cmap=&#39;gray&#39;) plt.show() . Take a look at more samples from the train set. . for i in range(5): sample_img, sample_msk = train_dataset[random.choice(range(len(train_dataset)))] plt.subplot(1,2,1) plt.title(&quot;Image&quot;) plt.axis(&quot;off&quot;) plt.imshow(sample_img.squeeze(), cmap=&#39;gray&#39;) plt.subplot(1,2,2) plt.title(&quot;Mask&quot;) plt.axis(&quot;off&quot;) plt.imshow(sample_msk.squeeze(), cmap=&#39;gray&#39;) plt.show() . Find the weight of positive and negative pixels. . The number of positive pixels is less than 1% of the total, showing that the dataset is highly imbalanced. . positive_weight = 0 negative_weight = 0 total_pixels = 0 img_shape = train_dataset[0][0].shape for _, target in train_dataset: positive_weight += (target &gt;= 0.5).sum().item() negative_weight += (target &lt; 0.5).sum().item() total_pixels += (img_shape[1] * img_shape[2]) positive_weight /= total_pixels negative_weight /= total_pixels print(&#39;positive weight = &#39;,positive_weight, &#39; tnegative weight = &#39;, negative_weight) . positive weight = 0.0022352430555555554 negative weight = 0.9977647569444444 . Create model and train . from itertools import islice def show_predictions_from_batch(model, dataloader, batch_num=0, limit = None): &quot;&quot;&quot; Method to visualize model predictions from batch batch_num. Show a maximum of limit images. &quot;&quot;&quot; batch = next(islice(iter(dataloader), batch_num, None), None) # Selects the nth item from dataloader, returning None if not possible. images, masks = batch with torch.no_grad(): model.eval() logits = model(images) pr_masks = logits.sigmoid() pr_masks = (pr_masks &gt;= 0.5)*1 for i, (image, gt_mask, pr_mask) in enumerate(zip(images, masks, pr_masks)): if limit and i == limit: break fig = plt.figure(figsize=(15,4)) ax = fig.add_subplot(1,3,1) ax.imshow(image.squeeze(), cmap=&#39;gray&#39;) ax.set_title(&quot;Image&quot;) ax.axis(&quot;off&quot;) ax = fig.add_subplot(1,3,2) ax.imshow(gt_mask.squeeze(), cmap=&#39;gray&#39;) ax.set_title(&quot;Ground truth&quot;) ax.axis(&quot;off&quot;) ax = fig.add_subplot(1,3,3) ax.imshow(pr_mask.squeeze(), cmap=&#39;gray&#39;) ax.set_title(&quot;Predicted mask&quot;) ax.axis(&quot;off&quot;) . We&#39;ll create a PyTorch Lightning module to help streamline the training process. In the class initalization, it uses the segmentation models library, via the call to smp.create_model, to build a PyTorch model which operates on one channel images for binary segmentation. Many state of the art models are possible with the segmentation models library. However, we&#39;ll typically use the Unet with resnet34 backbone. . We&#39;ll also use the segmentation models library to monitor the intersection over union metric. This will give us a much better indicator of model quality than the accuracy. . class SurfaceDefectModel(pl.LightningModule): def __init__(self, arch, encoder_name, loss = &quot;SoftBCEWithLogitsLoss&quot; , **kwargs): super().__init__() self.model = smp.create_model( arch, encoder_name=encoder_name, encoder_weights = None, in_channels=1, classes=1, **kwargs ) self.arch = arch self.encoder_name = encoder_name self.loss_name = loss if loss == &quot;DiceLoss&quot;: self.loss_fn = smp.losses.DiceLoss(smp.losses.BINARY_MODE, from_logits=True) elif loss == &quot;TverskyLoss&quot;: self.loss_fn = smp.losses.TverskyLoss(smp.losses.BINARY_MODE, from_logits=True, alpha=0.3,beta=0.7) elif loss == &quot;FocalLoss&quot;: self.loss_fn = smp.losses.FocalLoss(smp.losses.BINARY_MODE) else: self.loss_fn = smp.losses.SoftBCEWithLogitsLoss() self.printed_run_id = None self.run_id = None def forward(self, image): return self.model(image) def shared_step(self, batch, stage): image = batch[0] # Shape of the image should be (batch_size, num_channels, height, width) # if you work with grayscale images, expand channels dim to have [batch_size, 1, height, width] assert image.ndim == 4 # Check that image dimensions are divisible by 32, # encoder and decoder connected by `skip connections` and usually encoder have 5 stages of # downsampling by factor 2 (2 ^ 5 = 32); e.g. if we have image with shape 65x65 we will have # following shapes of features in encoder and decoder: 84, 42, 21, 10, 5 -&gt; 5, 10, 20, 40, 80 # and we will get an error trying to concat these features h, w = image.shape[2:] assert h % 32 == 0 and w % 32 == 0 mask = batch[1] # Shape of the mask should be [batch_size, num_classes, height, width] # for binary segmentation num_classes = 1 assert mask.ndim == 4 # Check that mask values in between 0 and 1, NOT 0 and 255 for binary segmentation assert mask.max() &lt;= 1.0 and mask.min() &gt;= 0 logits_mask = self.forward(image) # Predicted mask contains logits, and loss_fn param `from_logits` is set to True loss = self.loss_fn(logits_mask, mask) # Lets compute metrics for some threshold # first convert mask values to probabilities, then # apply thresholding prob_mask = logits_mask.sigmoid() pred_mask = (prob_mask &gt; 0.5).float() # We will compute IoU metric by two ways # 1. dataset-wise # 2. image-wise # but for now we just compute true positive, false positive, false negative and # true negative &#39;pixels&#39; for each image and class # these values will be aggregated in the end of an epoch tp, fp, fn, tn = smp.metrics.get_stats(pred_mask.long(), mask.long(), mode=&quot;binary&quot;) return { &quot;loss&quot;: loss, &quot;tp&quot;: tp, &quot;fp&quot;: fp, &quot;fn&quot;: fn, &quot;tn&quot;: tn, } def shared_epoch_end(self, outputs, stage): # aggregate step metics tp = torch.cat([x[&quot;tp&quot;] for x in outputs]) fp = torch.cat([x[&quot;fp&quot;] for x in outputs]) fn = torch.cat([x[&quot;fn&quot;] for x in outputs]) tn = torch.cat([x[&quot;tn&quot;] for x in outputs]) # per image IoU means that we first calculate IoU score for each image # and then compute mean over these scores per_image_iou = smp.metrics.iou_score(tp, fp, fn, tn, reduction=&quot;micro-imagewise&quot;) # dataset IoU means that we aggregate intersection and union over whole dataset # and then compute IoU score. The difference between dataset_iou and per_image_iou scores # in this particular case will not be much, however for dataset # with &quot;empty&quot; images (images without target class) a large gap could be observed. # Empty images influence a lot on per_image_iou and much less on dataset_iou. dataset_iou = smp.metrics.iou_score(tp, fp, fn, tn, reduction=&quot;micro&quot;) accuracy = smp.metrics.accuracy(tp, fp, fn, tn) metrics = { f&quot;{stage}_per_image_iou&quot;: per_image_iou, f&quot;{stage}_dataset_iou&quot;: dataset_iou, f&quot;{stage}_accuracy&quot;: accuracy, f&quot;{stage}_loss&quot;: torch.tensor([x[&quot;loss&quot;].item() for x in outputs]).mean() } # Log the metrics #for key, val in metrics.items(): # self.logger.experiment.log_metric(self.logger.run_id ,key, val.mean().item(), step=self.current_epoch) self.logger.log_metrics({key: val.mean().item() for key, val in metrics.items() }, step=self.current_epoch) # only record the loss in mlflow del metrics[f&quot;{stage}_loss&quot;] if not self.printed_run_id: print(self.logger.run_id ) self.printed_run_id = True # This will be available in tensorboard. self.log_dict(metrics, prog_bar=True) def training_step(self, batch, batch_idx): return self.shared_step(batch, &quot;train&quot;) def training_epoch_end(self, outputs): self.shared_epoch_end(outputs, &quot;train&quot;) def validation_step(self, batch, batch_idx): return self.shared_step(batch, &quot;valid&quot;) def validation_epoch_end(self, outputs): self.shared_epoch_end(outputs, &quot;valid&quot;) def test_step(self, batch, batch_idx): return self.shared_step(batch, &quot;test&quot;) def test_epoch_end(self, outputs): return self.shared_epoch_end(outputs, &quot;test&quot;) def configure_optimizers(self): return torch.optim.Adam(self.parameters(), lr=0.0001) def on_fit_end(self): # Log hyperparameters to mlflow. self.logger.experiment.log_param(self.logger.run_id ,&quot;arch&quot;, self.arch) self.logger.experiment.log_param(self.logger.run_id ,&quot;encoder_name&quot;, self.encoder_name) self.logger.experiment.log_param(self.logger.run_id ,&quot;loss&quot;, self.loss_name) self.run_id = self.logger.run_id . train_loader = DataLoader(train_dataset, batch_size=8, shuffle=True, num_workers=4) valid_loader = DataLoader(val_dataset, batch_size=1, shuffle=False, num_workers=4) . model = SurfaceDefectModel(&quot;Unet&quot;, &quot;resnet34&quot;) . Sanity check the model by showing its predictions. . show_predictions_from_batch(model, train_loader, batch_num=0, limit=1) . We&#39;ll use the ModelCheckpoint callback from PyTorch lightning to save the best model, as measured by the intersection over union metric. . from pytorch_lightning.callbacks import ModelCheckpoint from pathlib import Path checkpoint_callback = ModelCheckpoint( monitor=&quot;valid_dataset_iou&quot;, dirpath=&quot;./models&quot;, filename= f&quot;surface_defect_{model.arch}_{model.encoder_name}_{model.loss_name}&quot;, save_top_k=3, mode=&quot;max&quot;, ) # Add the model directory if it it doesn&#39;t exist Path(&quot;./models&quot;).mkdir(exist_ok=True) . Now with the help of PyTorch lightning, we can train and log to MLflow, with a few lines of code. . mlf_logger = MLFlowLogger(experiment_name=&quot;lightning_logs&quot;) trainer = pl.Trainer( gpus=1, max_epochs=200, callbacks=[checkpoint_callback], logger=mlf_logger, ) trainer.fit( model, train_dataloaders=train_loader, val_dataloaders=valid_loader, ) . GPU available: False, used: False TPU available: False, using: 0 TPU cores IPU available: False, using: 0 IPUs HPU available: False, using: 0 HPUs | Name | Type | Params -- 0 | model | Unet | 24.4 M 1 | loss_fn | SoftBCEWithLogitsLoss | 0 -- 24.4 M Trainable params 0 Non-trainable params 24.4 M Total params 97.720 Total estimated model params size (MB) Experiment with name lightning_logs not found. Creating it. . 0947cdf639374feab6d819b7ab2cfb0c . /opt/conda/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py:1933: PossibleUserWarning: The number of training batches (23) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch. rank_zero_warn( . Load the best model to analyze its performance. . model.load_from_checkpoint(f&quot;models/surface_defect_{model.arch}_{model.encoder_name}_{model.loss_name}.ckpt&quot;, arch = model.arch, encoder_name= model.encoder_name, loss = model.loss_fn.__class__.__name__) . SurfaceDefectModel( (model): Unet( (encoder): ResNetEncoder( (conv1): Conv2d(1, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False) (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (relu): ReLU(inplace=True) (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False) (layer1): Sequential( (0): BasicBlock( (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (relu): ReLU(inplace=True) (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) ) (1): BasicBlock( (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (relu): ReLU(inplace=True) (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) ) (2): BasicBlock( (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (relu): ReLU(inplace=True) (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) ) ) (layer2): Sequential( (0): BasicBlock( (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (relu): ReLU(inplace=True) (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (downsample): Sequential( (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False) (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) ) ) (1): BasicBlock( (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (relu): ReLU(inplace=True) (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) ) (2): BasicBlock( (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (relu): ReLU(inplace=True) (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) ) (3): BasicBlock( (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (relu): ReLU(inplace=True) (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) ) ) (layer3): Sequential( (0): BasicBlock( (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (relu): ReLU(inplace=True) (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (downsample): Sequential( (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False) (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) ) ) (1): BasicBlock( (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (relu): ReLU(inplace=True) (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) ) (2): BasicBlock( (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (relu): ReLU(inplace=True) (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) ) (3): BasicBlock( (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (relu): ReLU(inplace=True) (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) ) (4): BasicBlock( (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (relu): ReLU(inplace=True) (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) ) (5): BasicBlock( (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (relu): ReLU(inplace=True) (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) ) ) (layer4): Sequential( (0): BasicBlock( (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (relu): ReLU(inplace=True) (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (downsample): Sequential( (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False) (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) ) ) (1): BasicBlock( (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (relu): ReLU(inplace=True) (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) ) (2): BasicBlock( (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (relu): ReLU(inplace=True) (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) ) ) ) (decoder): UnetDecoder( (center): Identity() (blocks): ModuleList( (0): DecoderBlock( (conv1): Conv2dReLU( (0): Conv2d(768, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (2): ReLU(inplace=True) ) (attention1): Attention( (attention): Identity() ) (conv2): Conv2dReLU( (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (2): ReLU(inplace=True) ) (attention2): Attention( (attention): Identity() ) ) (1): DecoderBlock( (conv1): Conv2dReLU( (0): Conv2d(384, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (2): ReLU(inplace=True) ) (attention1): Attention( (attention): Identity() ) (conv2): Conv2dReLU( (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (2): ReLU(inplace=True) ) (attention2): Attention( (attention): Identity() ) ) (2): DecoderBlock( (conv1): Conv2dReLU( (0): Conv2d(192, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (2): ReLU(inplace=True) ) (attention1): Attention( (attention): Identity() ) (conv2): Conv2dReLU( (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (2): ReLU(inplace=True) ) (attention2): Attention( (attention): Identity() ) ) (3): DecoderBlock( (conv1): Conv2dReLU( (0): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (2): ReLU(inplace=True) ) (attention1): Attention( (attention): Identity() ) (conv2): Conv2dReLU( (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (2): ReLU(inplace=True) ) (attention2): Attention( (attention): Identity() ) ) (4): DecoderBlock( (conv1): Conv2dReLU( (0): Conv2d(32, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (2): ReLU(inplace=True) ) (attention1): Attention( (attention): Identity() ) (conv2): Conv2dReLU( (0): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (2): ReLU(inplace=True) ) (attention2): Attention( (attention): Identity() ) ) ) ) (segmentation_head): SegmentationHead( (0): Conv2d(16, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)) (1): Identity() (2): Activation( (activation): Identity() ) ) ) (loss_fn): SoftBCEWithLogitsLoss() ) . trainer.validate(model, dataloaders=valid_loader, verbose=False) . [{&#39;valid_per_image_iou&#39;: 0.0018078746506944299, &#39;valid_dataset_iou&#39;: 0.003512033959850669, &#39;valid_accuracy&#39;: 0.995513916015625}] . Visualize the model performance on the validation set. . for i in range(len(valid_loader)): show_predictions_from_batch(model, valid_loader, batch_num=i) . /tmp/ipykernel_23/3728964761.py:23: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`). fig = plt.figure(figsize=(15,4)) . Analyze best saved model on the Test set . test_loader = DataLoader(test_dataset, batch_size=8, shuffle=False, num_workers=4) . trainer.test(model, dataloaders=test_loader, verbose=False) . [{&#39;test_per_image_iou&#39;: 0.08222604542970657, &#39;test_dataset_iou&#39;: 0.010361794382333755, &#39;test_accuracy&#39;: 0.996726393699646}] . Finally, visualize the model performance on the test set. . for i in range(len(test_loader)): show_predictions_from_batch(model, test_loader, batch_num=i) . /tmp/ipykernel_23/3728964761.py:23: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`). fig = plt.figure(figsize=(15,4)) .",
            "url": "https://krishanr.github.io/fastpages/pytorch/segmentationmodels/pytorchlightning/mlflow/2022/06/30/surface-defect-segmentation.html",
            "relUrl": "/pytorch/segmentationmodels/pytorchlightning/mlflow/2022/06/30/surface-defect-segmentation.html",
            "date": " • Jun 30, 2022"
        }
        
    
  
    
        ,"post1": {
            "title": "How to build a Docker image with an Anaconda environment in Paperspace?",
            "content": "Paperspace is an affordable tool for obtaining cloud compute power. Using it, you can run jupyter notebooks, python scripts, or just about anything, provided you can write the right Docker file. Plus some of the compute instances also come with GPUs, making Paperspace an alternative to Google Colab. In contrast with Google Colab though, Paperspace saves the files you use, so they are there when you return. Inspired by Alex&#39;s post on Building my own image to use IceVision with Paperspace, in this post I&#39;ll describe how you can build a docker image to wrap an Anaconda environment, and then run it on Paperspace. The Dockerfile and Anaconda environment I used are available on Github here. . The context for this post is that even though a custom anaconda environment can be created and run in the Paperspace images that are readily available, for longer projects, it would be useful to use a Paperspace image that comes prebuilt with a desired environment. . We can do this by adding a few additional lines to the standard Paperspace Docker image. Any anconda environment available at &#39;environment.yml&#39; can be created and activated using these 4 lines: . ADD environment.yml $APP_HOME/environment.yml RUN conda env create -f $APP_HOME/environment.yml ENV PATH $CONDA_DIR/envs/tf2/bin:$PATH RUN echo &quot;source activate tf2&quot; &gt; ~/.bashrc . The first two commands add the conda environment file to the Docker containers workspace, and then create the conda environment. . The third command adds the enviornment directory to the PATH enviroment variable. The directory path contains the environment name, which in this case is tf2 (replace this with your environment name if necessary). Finally, the last command adds a command to activate the enviornment to the bashrc file, so that the environment is activated when the container is started. . That&#39;s it! The bulk of the work for creating and running a Docker image with an anaconda environment in Paperspace is done with the above 4 lines of code. . The entire Dockerfile is available on GitHub here. . Following Alex, I&#39;ll describe the steps to setup a Paperspace instance using this Dockerfile. . First go to your notebooks inside a project, and create a new Paperspace notebook. . . Next, choose a GPU instance to create the notebook (or CPU depending on the project), for example the RTX5000 option, and an automatic shutdown of 6 hours. . . Next the Dockerfile will have to be built and pushed to Dockerhub, before it can be used with paperspace. . To build the Dockerfile, just run . docker build -t k2rajara/paperspace:3.0 . for example, in the same directory as the Dockerfile. . In the above code, &#39;k2rajara/paperspace&#39; is the container name on Dockerhub. To create your own repository on Dockerhub, follow the instructions here. Then push your image there. Once this is complete, its details can be added to the advanced section: . . The command that is run in the container is the default one for Paperspace: . jupyter lab --allow-root --ip=0.0.0.0 --no-browser --ServerApp.trust_xheaders=True --ServerApp.disable_check_xsrf=False --ServerApp.allow_remote_access=True --ServerApp.allow_origin=&#39;*&#39; --ServerApp.allow_credentials=True . Finally after clicking &quot;Start Notebook&quot;, Paperspace should pull the image from Dockerhub and run jupyter lab as requested. . In my case, the conda environment I created is available on Github here and shown here: . name: tf2 channels: - conda-forge - defaults - anaconda dependencies: - python=3.6 - pip=21 - jupyterlab - jupyter_client=7.1.0 - jupyter_server=1.13.1 - tensorflow-gpu=2.2 - pip: - mlflow==1.11.0 - python-dotenv==0.15.0 - matplotlib==3.1.2 - Pillow==8.0.1 - scikit-image==0.17.2 - ruamel_yaml==0.16.12 . The project I was working on used python 3.6, and tensorflow 2.2. Due to the outated version of python, I also had to install the jupyter client and server manually, to avoid bugs. However, the environment can be customized depending on your project requirements. . For example, to create a minimal installation with tensorflow2 and jupyterlab, use: . name: tf2 channels: - anaconda dependencies: - jupyterlab - tensorflow-gpu .",
            "url": "https://krishanr.github.io/fastpages/docker/tools/2022/06/15/anaconda-in-docker-on-paperspace.html",
            "relUrl": "/docker/tools/2022/06/15/anaconda-in-docker-on-paperspace.html",
            "date": " • Jun 15, 2022"
        }
        
    
  
    
        ,"post2": {
            "title": "Principal component analysis",
            "content": "Principal component analysis (PCA) is a well known technique for dimensionality reduction, dating back over one hundred years. Here we&#39;ll summarize the theory and application of PCA, showing for example that it&#39;s most naturally applicable to multivariate normal data, which is determined by its first two moments. We shall derive PCA as a canonical form for random vectors, obtained using the population covariance matrix for a population or the sample covariance matrix for a sample. We&#39;ll also see how this decomposition differs when using the population correlation matrix or the sample correlation matrix instead. We conclude with a computation of PCA for the iris dataset, first from scratch using numpy, and then using the scikit-learn API. . We follow chapter 8 in (Johnson &amp; Wichern, 1982) for the theory of PCA, both in terms of populations of random variables and samples of random variables, and then apply it following chapter 8 in (Géron, 2017). We also follow Professor Helwig&#39;s notes available here. . By making a distinction between population and sample PCA, we can make statements about limits of the sample PCA as the sample size goes to infinity. Besides theoretical interest, these limits are useful for calculating confidence intervals, p-values, etc. . Note hereafter that all vectors are assumed to row vectors unless specified otherwise, and we&#39;ll use $ vec{1}$ to denote the row vector with components all equal to $1$. We&#39;ll also make the following definitions. Let $ vec{X} = (X_1, ..., X_p)$ be a random (row) vector. The vector has (population) mean $ vec{ mu} = mathbb{E}[ vec{X}]$ and (population) covariance matrix $ Sigma = mathbb{E}[( vec{X} - vec{ mu})^T( vec{X} - vec{ mu})] $. The (population) correlation matrix is . $$ P = begin{bmatrix} 1 &amp; rho_{12} &amp; rho_{13} &amp; dots &amp; rho_{1p} rho_{21} &amp; 1 &amp; rho_{23} &amp; dots &amp; rho_{2p} vdots &amp; vdots &amp; vdots &amp; ddots &amp; vdots rho_{p1} &amp; rho_{p2} &amp; rho_{p3} &amp; dots &amp; 1 end{bmatrix} $$where . $$ begin{aligned} rho_{jk} &amp; = frac{ sigma_{jk}}{ sqrt{ sigma_{jj} sigma_{kk} }}, &amp; sigma_{jk} &amp; = Sigma_{jk} end{aligned} $$is the Pearson correlation coefficient between variables $X_j$ and $X_k$. . Transformations of random vectors . For $ vec{v}, vec{u} in mathbb{R}^p$, let $Y = vec{X} vec{v}^T = vec{X} cdot vec{v}$ and $Z = vec{X} cdot vec{u}$, then one can show that . $$ begin{aligned} mathbb{E}[Y] &amp; = vec{ mu} cdot vec{v} operatorname{cov}[Y, Z] &amp; = vec{v} : Sigma : vec{u}^T end{aligned} $$More generally, with $v_1, dotsc,v_q in mathbb{R}^p$ and $c in mathbb{R}^q$, let $Y = vec{X} cdot vec{v_i}$, and define the $q times p$ matrix $V$ by: . $$ V = begin{bmatrix} vec{v}_1 vdots vec{v}_q end{bmatrix} $$so that $ vec{Y} = vec{X} cdot V^T$, then . $$ begin{aligned} mathbb{E}[ vec{Y} + c] &amp; = vec{ mu} cdot V^T + c operatorname{cov}[ vec{Y} + c ] &amp; = operatorname{cov}[ vec{X} cdot V^T] = V ; Sigma_X ; V^T end{aligned} $$Also note that . $$ sum_{j=1}^q operatorname{Var}(Y_j) = operatorname{tr}( operatorname{cov}[ vec{Y}]) = operatorname{tr}(V ; Sigma_X ; V^T) = operatorname{tr}( Sigma_X ; V^T V) $$ . by the cyclic property of the trace. Hence when $q = p$ and $V$ is orthonormal, . $$ sum_{j=1}^p operatorname{Var}(Y_j) = operatorname{tr}( operatorname{cov}[ vec{Y}]) = operatorname{tr}(A ; Sigma_X ; A^T) = operatorname{tr}( Sigma_X ) = sum_{j=1}^p operatorname{Var}(X_j) $$ . Spectral theorem for symmetric matricies . Recall for any $p times p$ symmetric matrix $ Sigma$, if we let $ lambda_1 geq lambda_2 geq dots geq lambda_p geq 0$ be the eigenvalues of $ Sigma$, then . $$ begin{aligned} lambda_1 &amp; = operatorname{max}_{x neq 0} frac{ vec{x} : Sigma : vec{x}^T}{ lVert x rVert^2} lambda_p &amp; = operatorname{min}_{x neq 0} frac{ vec{x} : Sigma : vec{x}^T}{ lVert x rVert^2} frac{ lambda_1}{ lambda_p} &amp; = kappa( Sigma) = operatorname{max}_{x , y neq 0} frac{ vec{x} : Sigma : vec{x}^T}{ lVert x rVert^2} frac{ lVert x rVert^2}{ vec{y} : Sigma : vec{y}^T} end{aligned} $$where $ kappa( Sigma)$ is the condition number of $ Sigma$, defined when $ Sigma$ is positive definite. There are also similar formulas for the other eigenvalues defined on appropriate subspaces. . Finally, since the covariance matrix $ Sigma$ is positive semi-definite, the spectral theorem applies to it, which we shall review later. This together with the fact that any random variable with zero variance is zero implies that $ Sigma$ is positive definite iff the random variables $X_1, ..., X_p$ are linearly independent. . Two dimensions . Here&#39;s a useful corollary of the above transformation law for the covariance matrix. Suppose $X_1$ and $X_2$ are random variables with covariance matrix $ Sigma_X$. Then the variables $Y_1$ and $Y_2$ defined by . $$ begin{aligned} Y_1 &amp; = X_1 - X_2 Y_2 &amp; = X_1 + X_2 end{aligned} $$have covariance . $$ Sigma_Y = operatorname{cov}[ vec{Y}] = begin{bmatrix} sigma_{11} - 2 sigma_{12} + sigma_{22} &amp; sigma_{11} - sigma_{22} sigma_{11} - sigma_{22} &amp; sigma_{11} + 2 sigma_{12} + sigma_{22} end{bmatrix} $$Thus $Y_1$ and $Y_2$ are uncorrelated iff $X_1$ and $X_2$ have the same variance, i.e. $ sigma_{11} = sigma_{22}$. . Moreover if $X_1$ and $X_2$ are independent, then $Y_1$ and $Y_2$ are in general not independent. In fact, if $Y_1$ and $Y_2$ are also independent, then $X_1$ and $X_2$ are normal random variables (see here). This fact is known as Bernstein&#39;s theorem, and holds for more general linear combinations. . Thus a unitary transformation of iid random variables have the same covariance matrix but are not in general independent. . Population PCA . As above let $ vec{Y} = vec{X} cdot V^T$ where $V$ is a $pxp$ matrix. Then the formula . $$ Sigma_Y = operatorname{cov}[ vec{Y}] = V ; Sigma_X ; V^T $$ . shows that $ Sigma_Y$ and $ Sigma_X$ are similar quadratic forms. Thus since $ Sigma_X$ is symmetric, by the spectral theorem there exists a new set of random variables $Y_1, dotsc, Y_p$ in which $ Sigma_Y$ is diagonal. These are the principal components of the random vector $ vec{X}$, which can also be defined using notations from probability theory as follows: . $$ begin{aligned} text{First principal component } = Y_1 = &amp; text{ linear combination of } vec{X} vec{v}_1^T text{ that maximizes } &amp; operatorname{Var}[ vec{X} vec{v}_1^T] text{ subject to } lVert vec{v}_1 rVert = 1 text{Second principal component } = Y_2 = &amp; text{ linear combination of } vec{X} vec{v}_2^T text{ that maximizes } &amp; operatorname{Var}[ vec{X} vec{v}_2^T] text{ subject to } lVert vec{v}_2 rVert = 1 text{ and } vec{v_2} : Sigma : vec{v_1}^T = operatorname{Cov}[ vec{X} vec{v}_1^T, vec{X} vec{v}_2^T] = 0 &amp; vdots text{Last principal component } = Y_p = &amp; text{ linear combination of } vec{X} vec{v}_p^T text{ that maximizes } &amp; operatorname{Var}[ vec{X} vec{v}_p^T] text{ subject to } lVert vec{v}_p rVert = 1 text{ and } operatorname{Cov}[ vec{X} vec{v}_p^T, vec{X} vec{v}_1^T] = operatorname{Cov}[ vec{X} vec{v}_p^T, vec{X} vec{v}_2^T] = dots = operatorname{Cov}[ vec{X} vec{v}_p^T, vec{X} vec{v}_{p-1}^T] = 0 end{aligned} $$Equivalently, let $( lambda_1, vec{e}_1)$, $( lambda_2, vec{e}_2)$, ..., $( lambda_p, vec{e}_p)$ be the eigenvalue-eigenvector pairs of $ Sigma$ with the eigenvalues ordered in non-increasing order. Then the ith principal component is: . $$ Y_i = vec{X} vec{e}_i^T quad, i = 1,...,p $$with . $$ begin{aligned} operatorname{Var}[Y_i] &amp; = lambda_i quad i = 1,...,p operatorname{Cov}[Y_i, Y_j] &amp; = 0 quad i neq j end{aligned} $$Thus the ith maximal variance of $ Sigma$ is the ith eigenvalue of $ Sigma$. . Also note that only unique eigenvalues have unique eigenvectors (up to sign), so the principal components are in general not unique. . The above formula for the trace implies that the random variables $Y_1, ..., Y_p$ have the same total variance as $X_1, ..., X_p$, since . $$ sum_{j=1}^p operatorname{Var}(X_j) = operatorname{tr}( Sigma) = operatorname{tr}(V ; Sigma_X ; V^T ) = operatorname{tr}( Sigma_X) = sum_{j=1}^p operatorname{Var}(Y_j) = sum_{j=1}^p lambda_j $$ . Thus we can define the proportion of variance captured by the $k$th principal component as . $$ begin{aligned} &amp; text{Proporition of variance due } = frac{ lambda_k}{ sum_{j=1}^p lambda_j}, quad k= 1,...,p &amp; text{to the $k$th principal component } end{aligned} $$The basic idea behind PCA for dimensionality reduction is to only keep the the first $k$ principal components which captures, say $90 %$, of the variance, thereby reducing the number of variables. . Another way to select the principal components is to choose the most variables possible such that the conditon number (ratio of largest to smallest eigenvalues) of the reduced covariance matrix is close to $1$. This is because machine learning algorithms, like linear and logistic regression, preform better (more precision and faster convergence for gradient based methods) when the condition number of the covariance matrix is close to $1$. . Population PCA using the correlation matrix . PCA can also be calculated using the correlation matrix $P$ which is the covariance matrix of the standardized features having their mean set to $0$ and variance to $1$. Specifically, one applies the above calculations to the following variables: . $$ begin{aligned} Z_1 &amp;= frac{X_1 - mu_1}{ sqrt{ sigma_{11}}} Z_2 &amp;= frac{X_2 - mu_2}{ sqrt{ sigma_{22}}} vdots &amp; quad vdots Z_p &amp;= frac{X_p - mu_p}{ sqrt{ sigma_{pp}}} end{aligned} $$In matrix notation we have . $$ begin{aligned} vec{Z} &amp;= ( vec{W}^{ frac{1}{2}})^{-1}( vec{X} - vec{ mu}) operatorname{cov}[ vec{Z}] &amp; = ( vec{W}^{ frac{1}{2}})^{-1} ; Sigma ; ( vec{W}^{ frac{1}{2}})^{-1} = P end{aligned} $$where $ vec{W} = operatorname{diag}( sigma_{11},..., sigma_{pp})$. Then one obtains a decomposition similar to above with the following difference in the formula: . $$ sum_{j=1}^p operatorname{Var}(Y_j) = sum_{j=1}^p operatorname{Var}(X_j) = p $$Then the formula for the proportion of variance captured by the $k$th principal component simplifies to: . $$ begin{aligned} &amp; text{Proporition of variance due } = frac{ lambda_k}{p}, quad k= 1,...,p &amp; text{to the $k$th principal component } end{aligned} $$It&#39;s important to note that the principal components calculated from $ Sigma$ and $P$ can differ significantly, being a different linear combination of the original variables (Example 8.2 in (Johnson &amp; Wichern, 1982)). The principal components are similar when the variances for the $p$ random variables are the same, $ sigma = sigma_{11} = sigma_{22} = dots = sigma_{pp}$. Finally note that it&#39;s good practise to work with variables on the same scales so that the principal components aren&#39;t heavily skewed towards the larger variables. . Sample PCA . Consider $n$ iid realizations $ vec{X}_1, ..., vec{X}_n$ from the random vector $ vec{X}$. We can arrange this data into a feature matrix . $$ X = begin{bmatrix} vec{X}_1 vdots vec{X}_n end{bmatrix} $$The sample covariance matrix, $S$, is: . $$ begin{aligned} S_{i j} = frac{1}{n-1} sum_{k=1}^n (X_{k i} - bar{X}_i) (X_{k j} - bar{X}_j) = frac{1}{n-1} (X - vec{1} otimes bar{X})^T (X - bar{X} otimes vec{1}) end{aligned} quad quad i= 1,...,p text{ and } j = 1,...,p$$and the sample correlation matrix, $R$, is: . $$ begin{aligned} R_{ij} = frac{S_{ij}}{ sqrt{S_{ii}} sqrt{S_{jj}}} = frac{ sum_{k=1}^n (X_{k i} - bar{X}_i) (X_{k j} - bar{X}_j)}{ sqrt{ sum_{k=1}^n (X_{k i} - bar{X}_i)^2 } sqrt{ sum_{k=1}^n (X_{k j} - bar{X}_j)^2}} end{aligned} quad quad i= 1,...,p text{ and } j = 1,...,p $$For $ vec{v} in mathbb{R}^p$ a new feature is defined by the equation . $$ Y = vec{X} cdot vec{v} $$ . Formulas similar to above show that the sample covariance matrix transforms according to (see chapter 8 in (Johnson &amp; Wichern, 1982)): . $$ S_Y = V S_X V^T $$ . Thus an identical construction can be given for the principal components, now using $S$ in place of $ Sigma$, or $R$ in place of $P$. . Reconstruction error . Let $W_d = [ v_1 dots v_d ]$ be the matrix whose columns are the first $d$ eigenvectors of $S_X$ (ordered from largest to smallest eigenvalue). Then given any feature vector $ vec{X}_i$, the vector $ vec{X}_i W_d$ is the $d$ dimensional projection, and the vector $ vec{X}_i W_d W_d^T$ is the reconstructed vector. There&#39;s a fairly simple formula for the reconstruction error . $$ sum_{i=1}^n || vec{X}_i W_d W_d^T - vec{X}_i||^2 $$It turns out that (see chapter 9 in (Johnson &amp; Wichern, 1982) for a proof) . $$ begin{aligned} sum_{i=1}^n || vec{X}_i W_d W_d^T - vec{X}_i||^2 &amp; = operatorname{tr}[(X W_d W_d^T - X)(X W_d W_d^T - X)^T] &amp; vdots &amp; = lambda_{d+1} + dots + lambda_p end{aligned} $$Thus the recontruction error of the $d$ dimensional projection is equal to the remaining $p-d$ eigenvalues of the covariance matrix, i.e. the unexplained variance. Finally, note that this is the smallest possible error among all $d$ dimensional projections, and this is another defining property of PCA. . Large sample properties . As expected, when the feature matrix $X$ comes from a multivariate Gaussian, the principal components recover the natural frame which diagonalizes the covariance matrix of the Gaussian. In fact, much more can be said. . When $ vec{X}_i overset{iid}{ sim} N( vec{ mu}, vec{ Sigma})$ and the eigenvalues of $ Sigma$ are strictly positive and unique: $ lambda_1 &gt; dots lambda_p &gt; 0$, we can describe the large sample properties of the principal directions and eigenvalues. Then as $n rightarrow infty$, we have ((Johnson &amp; Wichern, 1982)): . $$ sqrt{n}( hat{ vec{ lambda}} - vec{ lambda}) approx N( vec{0}, 2 vec{ Lambda}^2) sqrt{n}( hat{ vec{v}}_k - vec{v}_k) approx N( vec{0}, vec{V}_k) $$where $ Lambda = operatorname{diag}( lambda_1, ..., lambda_k)$ and . $$ vec{V}_k = lambda_k sum_{l neq k} frac{ lambda_l}{( lambda_l - lambda_k)^2} vec{v}_l^T vec{v}_l $$Furthermore, as $n rightarrow infty$, we have that $ hat{ lambda}_k$ and $ hat{ vec{v}}_k$ are independent. . Practical considerations . Below we follow A. Geron&#39;s notes on PCA to implement it in numpy and sckit-learn for the iris dataset. . import pandas as pd from sklearn import datasets from sklearn.decomposition import PCA import numpy as np iris = datasets.load_iris() . print(iris[&#39;feature_names&#39;]) . [&#39;sepal length (cm)&#39;, &#39;sepal width (cm)&#39;, &#39;petal length (cm)&#39;, &#39;petal width (cm)&#39;] . df = pd.DataFrame(iris[&#39;data&#39;], columns=[&#39;sepal_length&#39;, &#39;sepal_width&#39;, &#39;petal_length&#39;, &#39;petal_width&#39;]) df.head(5) . sepal_length sepal_width petal_length petal_width . 0 5.1 | 3.5 | 1.4 | 0.2 | . 1 4.9 | 3.0 | 1.4 | 0.2 | . 2 4.7 | 3.2 | 1.3 | 0.2 | . 3 4.6 | 3.1 | 1.5 | 0.2 | . 4 5.0 | 3.6 | 1.4 | 0.2 | . df.describe() . sepal_length sepal_width petal_length petal_width . count 150.000000 | 150.000000 | 150.000000 | 150.000000 | . mean 5.843333 | 3.057333 | 3.758000 | 1.199333 | . std 0.828066 | 0.435866 | 1.765298 | 0.762238 | . min 4.300000 | 2.000000 | 1.000000 | 0.100000 | . 25% 5.100000 | 2.800000 | 1.600000 | 0.300000 | . 50% 5.800000 | 3.000000 | 4.350000 | 1.300000 | . 75% 6.400000 | 3.300000 | 5.100000 | 1.800000 | . max 7.900000 | 4.400000 | 6.900000 | 2.500000 | . Since the units of each feature are comparable (the standard deviations are of the same order of magnitude), we will calculate PCA using the sample covariance matrix. If on the otherhand, the magnitudes differed by orders of magnitude, we would calculate PCA using the sample correlation matrix. . PCA using SVD directly . The principal components can be calculated by diagonalizing the covariance matrix or calulating the singular value decomposition of the feature matrix. We&#39;ll use the latter for numerical reasons. . X = iris[&#39;data&#39;] . The SVD of $X$ is calculated after subtracting off the sample mean. We&#39;ll call this matrix $X_{centered}$ and work with it hereafter. Then the SVD of $X_{centered}$ is . $X_{centered} = U D V^T$ . where $U$ is an $n times n$ orthonormal matrix, $V$ is an $m times m$ orthonormal matrix, and $D = operatorname{diag}(d_{11}, ..., d_{mm})$ is an $n times m$ rectangular diagonal matrix. . The matrix $V$ is the matrix of eigenvectors from the sample PCA above, and the diagonal covariance matrix $S_Y$ is obtained by squaring the singular values and dividing by $n-1$: . $$ S_Y = frac{1}{n-1} begin{bmatrix} d_{11}^2 &amp; &amp; &amp; ddots &amp; &amp; &amp; d_{mm}^2 end{bmatrix} $$For this example, we have: . X_centered = X - X.mean(axis=0) U, D, Vt = np.linalg.svd(X_centered) V = Vt.T eigs = D ** 2 . The $d$-dimensional projection can be calcualted using the $p times d$ matrix $W_d$ whose $d$ columns are the first $d$ eigenvectors. . $X_{d-proj} = X_{centered} W_d$ . W2 = V[:, :2] # W2 can also be obtained from the sklearn package using: pca.components_.T X2D_diy = X_centered @ W2 X2D_diy.shape . (150, 2) . Obtain the reconstructed data using: . $ X_{recovered} = X_{d-proj} W_{d}^T$ . A defining property of PCA is that for any dimension $d &lt; m$, the PCA reconstruction of the data minimizes the mean squared error between the original data among all possible $d$ dimensional hyperplanes. Moreover, the square of this error is equal to the sum of the $m-d$ smaller eigenvalues, as we shall see. . X_recovered = X2D_diy @ W2.T . The squared error is then: . np.linalg.norm(X_centered - X_recovered)**2 . 15.204644359438948 . Which is equal to the sum of the two smaller eigenvalues: . sum(eigs[2:]) . 15.204644359438953 . The proportion of the total sample variance due to each sample principal component is: . $$ frac{ hat{ lambda_i}}{( sum_{i=1}^m hat{ lambda_i}) } quad quad quad i = 1,...,m $$and is given numerically by . eigs/sum(eigs) . array([0.92461872, 0.05306648, 0.01710261, 0.00521218]) . We can obtain the number of principal components to retain by either (i) retaining the first $d$ components which sum up to 95% of the total variance, or (ii) looking for an elbow in the scree plot. . import matplotlib.pyplot as plt plt.plot(range(1,len(eigs)+1), np.array(eigs.tolist())) plt.title(label=&quot;Scree plot&quot;) plt.xlabel(&quot;i&quot;) plt.ylabel(&quot;lambda_i&quot;) plt.show() . There is an elbow in the plot at $i = 2$, meaning all eigenvalues after $ lambda_1$ are relatively small and about the same size. In this case, it appears that the first principal component effectively summarize the total sample variance. . Finally, we can visualize the two dimensional projection using a scatter plot. . plt.title(&quot;PCA with 2 principal components&quot;, fontsize=14) plt.scatter(X2D_diy[:, 0], X2D_diy[:,1], c=iris[&#39;target&#39;]) plt.xlabel(&quot;$y_1$&quot;, fontsize=18) plt.ylabel(&quot;$y_2$&quot;, fontsize=18) plt.show() . PCA using scikit-learn . Now we&#39;ll calculate the PCA projection using scikit-learn. Notice that scikit-learn will mean center the data itself. . pca = PCA(n_components = 2) X2D = pca.fit_transform(X) . Instead of specifing the number of components in the call to PCA above, we can also set $ operatorname{n _components}=0.95$ to obtain the number of dimensions which capture 95% of the variance in the data. Or we could pass in no arguments to get the full SVD and plot a scree plot. . Below, we check that sklearn PCA and the one calculated with SVD directly give the same answer. . np.max(X2D - X2D_diy) . 2.748330173586095 . The non-uniquness of the PCA leads to a large difference. However, this can be fixed by inspecting the projections and adjusting: . X2D_diy[:,1] = - X2D_diy[:,1] np.max(X2D - X2D_diy) . 1.3322676295501878e-15 . The explained variance ratio holds the proportion of variance explained by the first two sample principal components, and is given by . pca.explained_variance_ratio_ . array([0.92461872, 0.05306648]) . Computational complexity . Let $n_{max} = operatorname{max}(m,n)$ and $n_{min} = operatorname{min}(m,n)$. If $n_{max} &lt; 500$ and $d$ is less than $80 %$ of $n_{min}$, then scikit-learn uses the full SVD approach which has a complexity of $O(n_{max}^2 n_{min})$, otherwise it uses randomized PCA which has a complexity of $O(n_{max}^2 d)$ (cf. here and (Géron, 2017)). . There are many more variations of PCA, and other dimensionality reduction algorithms. See Decomposing signals in components (matrix factorization problems) in the scikit-learn documentation, for example. . Johnson, R. A., &amp; Wichern, D. W. (1982). Applied Multivariate Statistical Analysis. | Géron, A. (2017). Hands-On Machine Learning with Scikit-Learn and TensorFlow: Concepts, Tools, and Techniques to Build Intelligent Systems. | .",
            "url": "https://krishanr.github.io/fastpages/statistics/2022/03/30/principal-component-analysis.html",
            "relUrl": "/statistics/2022/03/30/principal-component-analysis.html",
            "date": " • Mar 30, 2022"
        }
        
    
  
    
        ,"post3": {
            "title": "Standard probability distributions",
            "content": "We&#39;ll review elementary univariate probability distributions in statistics, including how the mean/variance are derived, simple relationships, and the questions they answer, with calculations done in scipy. . This review is similar in spirit to brand name distributions and univariate distribution relationships. . import scipy.special as sp import scipy.stats as ss import numpy as np import matplotlib.pyplot as plt import seaborn as sns . The univariate probability distributions answer questions about events occuring on a discrete time interval $D_n = [0, 1, dotsc, n ]$ or a continuous time interval $I_t = [0, t]$. . In the discrete case each event could be a success with probability $p$ or a failure with probability $1-p$, with different events being independent. Then we can ask the following questions: . For fixed $n$, what is the probability of observing $k$ successes? | How many events do we have to observe before seeing $1$ success or more generally, $r$ successes? | The first question is answered by the Binomial distribution, and the second is answered by the geometric and negative binomial distributions. A concrete example of such events are coin tosses, where the outcome of each toss is independent of previous tosses, and each toss comes up as heads with probability $p = frac{1}{2}$. . In the case of a continuous time interval $I_t$ there are many types of events that can occur, but we&#39;ll study the simplest type with real world applications, the events associated with a Poisson process. Then we can ask the following questions about a Poisson process: . Within a fixed time $t$, what is the probability of observing $k$ events? | How much time do we have to wait before seeing the first event or more generally, $r$ events? | The first question is answered by the Poisson distribution, and the second is answered by the exponential and Erlang (Gamma) distributions. A concrete example of events following a Poisson process are the distribution of earthquakes in a given region. . Finally, the normal distribution will arise as the limiting distribution in the famous central limit theorem. . Moving forward, do remember that . $$ operatorname{var}[X] = mathbb{E}[(X - mathbb{E}[X] )^2] = mathbb{E}[X^2] - ( mathbb{E}[X])^2 $$ . Bernoulli distribution . Suppose X is a random variable denoting having a trial with a probability of success $p$. It gives a success, $X = 1$, with probability $p$ and failure, $X = 0$, with probability $1-p$. Then $X sim operatorname{Ber}(p)$, and . $$ mathbb{E}[X] = p, : : mathbb{E}[(X - mathbb{E}[X] )^2] = p (1-p)$$ . p = 0.4 rv = ss.bernoulli(p) mean, var, skew, kurt = rv.stats(moments=&#39;mvsk&#39;) print(&quot;mean {}, var {}, skew {}, kurt {}&quot;.format(mean, var, skew, kurt)) . mean 0.4, var 0.24, skew 0.40824829046386296, kurt -1.8333333333333337 . rv.interval(0.99) . (0.0, 1.0) . fig, ax = plt.subplots() y = np.random.binomial(1, p, size=100) sns.countplot(x=y, label=f&#39;mean = {y.mean(): 0.3f}&#39;, ax=ax) ax.legend(loc=&#39;upper right&#39;) ax.set(title=&#39;Bernoulli Distribution&#39;, xlabel=&#39;y&#39;); . P(X = 1) is calculated using the probability mass function below: . rv.pmf(1) . 0.4 . Binomial distribution . When we have $n$ independent trials, each with a probability of success $p$ and failure $1-p$, then $X sim operatorname{Bin}(n, p)$ which is a sum of $n$ independent $ operatorname{Ber}(p)$ random variables. I.e. letting $X_i sim operatorname{Ber}(p)$ for $i = 1, dotsc, n$, then . $$ X = sum_{i=1}^n X_i $$ . and a straightforward calculation gives . $$ mathbb{E}[X] = n p, : : mathbb{E}[(X - mathbb{E}[X] )^2] = n p (1-p)$$ . p, n = 0.4, 10 rv = ss.binom(n, p) mean, var, skew, kurt = rv.stats(moments=&quot;mvsk&quot;) print(&quot;mean {}, var {}, skew {}, kurt {}&quot;.format(mean, var, skew, kurt)) . mean 4.0, var 2.4, skew 0.12909944487358052, kurt -0.1833333333333334 . fig, ax = plt.subplots() y = np.random.binomial(n, p, size=200) sns.countplot(x=y, label=f&#39;mean = {y.mean(): 0.3f}&#39;, ax=ax) ax.legend(&quot;upper right&quot;) ax.set(title=&quot;Binomial distribution&quot;, xlabel=&quot;y&quot;); . P(X = 3) is calculated using the probability mass function below: . rv.pmf(3) . 0.21499084799999976 . Do a quick check that the probability mass function is normalized: . sum (rv.pmf(i) for i in range(n+1)) . 0.9999999999999994 . Geometric distribution . Suppose independent trials, each with a probability of success $p$, are performed until success occurs. Then the number of trials until the first success occurs is a random variable $X sim operatorname{Geo}(p)$, and called a geometric random variable. Its probability mass function is: . $$ P(X= n) = (1-p)^{n-1} p, : : n= 1,2, dotsc $$ . Using the probability generating function we calculate: . $$ mathbb{E}[X] = frac{1}{p}, : : mathbb{E}[(X - mathbb{E}[X] )^2] = frac{1-p}{p^2}$$ . p = 0.4 rv = ss.geom(p) mean, var, skew, kurt = rv.stats(moments=&quot;mvsk&quot;) print(&quot;mean {}, var {}, skew {}, kurt {}&quot;.format(mean, var, skew, kurt)) . mean 2.5, var 3.749999999999999, skew 2.0655911179772892, kurt 6.2666666666666675 . fig, ax = plt.subplots() y = np.random.geometric(p, size=1000) sns.countplot(x=y, label =f&#39;mean = {y.mean(): 0.3f}&#39;, ax=ax) ax.legend(&quot;upper right&quot;) ax.set(title=&quot;Geometric Distribution&quot;, xlabel=&quot;y&quot;); . As the above histogram hints at, the geometric distribution is the discretization of the exponential distribution, and shares the memoryless property: . $$ P(X &gt; n + k | X &gt; k) = P(X &gt; n) $$ . Negative Binomial distribution . Suppose independent trials, each with a probability of success $p$, are performed until success occurs (with the last trial being a success). Then the number of trials until $r$ successes occur is a random variable $X sim operatorname{NegBin}(r,p)$ and called a negative binomial random variable, which can be expressed as a sum of $r$ independent geometric distributions $X_i sim operatorname{Geo}(p)$ for $i = 1, dotsc, n$. . $$ X = X_1 + X_2 + dotsc + X_n $$ . The probability mass function is: . $$ P(X = k) = { k + r - 1 choose k} p^r (1-p)^{k} $$ . where $k$ is the number of failures seen before seeing a total of $r$ successes. . $$ mathbb{E}[X] = frac{r (1-p)}{p}, : : mathbb{E}[(X - mathbb{E}[X] )^2] = r frac{(1-p)}{p^2}$$ . p = 0.4 r = 4 rv = ss.nbinom(r, p) mean, var, skew, kurt = rv.stats(moments=&quot;mvsk&quot;) print(&quot;mean {}, var {}, skew {}, kurt {}&quot;.format(mean, var, skew, kurt)) . mean 5.999999999999999, var 14.999999999999996, skew 1.0327955589886446, kurt 1.5666666666666669 . fig, ax = plt.subplots() y = np.random.negative_binomial(r, p, size=1000) sns.countplot(x=y, label=f&#39;mean = {y.mean(): 0.3f}&#39;, ax=ax) ax.legend(&quot;upper right&quot;) ax.set(title=&quot;Negative Binomial distribution&quot;, xlabel=&quot;y&quot;); . Poisson distribution and processes . The number of events occuring in a fixed time interval $t$, with each event occuring independently of each other and at a average constant rate $ lambda$ is described by the Poisson distribution with parameter $ mu = lambda t$, $X sim Poi( mu)$, and has the probability mass function: . $$ P(X = k) = frac{ mu^k}{k!} e^{- mu} : : k = 0,1, dotsc$$ . The standard moments are, . $$ mathbb{E}[X] = mu = lambda t, : : mathbb{E}[(X - mathbb{E}[X] )^2] = mu$$ . Note that the time till the first event in a Poisson process is described by the exponential distribution with parameter $ lambda$, and the time till the first $r$ events in a Poisson process is described by the Erlang (Gamma) distribution with shape $r$ and rate $ lambda$. See below for definitions. . Also see section 20.2 from the stats cookbook for a good summary of the Poisson process and the different distributions involved. . mu = 6 rv = ss.poisson(mu) mean, var, skew, kurt = rv.stats(moments=&quot;mvsk&quot;) print(&quot;mean {}, var {}, skew {}, kurt {}&quot;.format(mean, var, skew, kurt)) . mean 6.0, var 6.0, skew 0.408248290463863, kurt 0.16666666666666666 . fig, ax = plt.subplots() y = np.random.poisson(mu, size=1000) sns.countplot(x=y, label=f&#39;mean = {y.mean(): 0.3f}&#39;, ax=ax) ax.legend(&quot;upper right&quot;) ax.set(title=&quot;Poisson distribution&quot;, xlabel=&quot;y&quot;); . Gamma function and distribution . Recall the Gamma function, $ Gamma( alpha)$, is a function of a real variable, such that $ Gamma( alpha) = alpha!$ for $ alpha = 0, 1, 2 dotsc$. . The Gamma distribution then has the probability distribution: . $$f(x; alpha, beta) = frac{x^{ alpha-1} e^{- beta x} beta^ alpha}{ Gamma( alpha)} text{ for } x &gt; 0$$ . with $ alpha &gt;0$ called the shape and $ beta &gt;0 $ called the rate. $ theta = 1/ beta$ is also called the scale parameter. . If $X sim operatorname{Ga}( alpha, beta)$ (see (Murphy, 2012)), then the standard moments are . $$ mathbb{E}[X] = frac{ alpha}{ beta}, : : mathbb{E}[(X - mathbb{E}[X] )^2] = frac{ alpha}{ beta^2}$$ $$ operatorname{mode}{X} = frac{( alpha-1)}{ beta} $$ . We parameterize the Gamma distribution in scipy as follows. . alpha, beta = 3, 1 rv = ss.gamma(a=alpha,scale=1/beta) . rv.interval(0.99) . (0.33786338872773347, 9.273792089255544) . fig, ax = plt.subplots(1, 1) x = np.linspace(0, rv.ppf(0.999), 100) ax.plot(x, rv.pdf(x), &#39;r-&#39;, lw=2, alpha=0.6, label=&#39;gamma pdf&#39;) ax.set(title=&quot;Gamma PDF&quot;, xlabel=&quot;y&quot;); . Exponential distribution . The Exponential, Erlang, and Chi-Squared distributions are all related to the Gamma distribution (Murphy, 2012), but we&#39;ll describe the simplest, the exponential distribution. . $$ operatorname{Exp}(x | lambda) = operatorname{Ga}(x | 1, lambda)$$ . where $ lambda$ is the rate parameter. The exponential distribution describes the waiting time between events in a Poisson process. . From the above formulas, if $X sim operatorname{Exp}(x | lambda)$, then . $$ mathbb{E}[X] = frac{1}{ lambda}, : : mathbb{E}[(X - mathbb{E}[X] )^2] = frac{1}{ lambda^2}$$ $$ operatorname{mode}{X} = 0 $$ . The exponential distribution, which is the continuous analog of the geometric distribution, also has the memoryless property: . $$ P(X &gt; t + h | X &gt; h) = P(X &gt; t )$$ . for any $t, h &gt; 0 $. . Characteristic functions of random variables . The charactierstic function will be useful for working with these distributions. . The characteristic function (also called the Fourier transform) of a random variable $X$ is . $$ phi(t) = mathbb{E}[e^{i t X}] : : text{ for } t in mathbb{R}$$ . This function satisfies $| phi(t)| &lt;= 1$ for all $t$ and is uniformly continuous. It has some advantages over the moment generating function, including the fact that it&#39;s defined everywhere, and that it uniquely determines the random variable (Grimmett &amp; Stirzaker, 2001). . Some other facts that we can derive from characteristic functions: . If $ phi^k(0)$ and $ mathbb{E}[|X^k|] &lt; infty$, then | $$ phi^k(0) = i^k mathbb{E}[X^k] $$ . If $X_1, X_2, dotsc, X_n$ are independent then | $$ phi_{X_1 + dotsc + X_n}(t) = phi_{X_1}(t) dots phi_{X_n}(t) $$ . If $a, b in mathbb{R}$ and $Y = a X + b $ then | $$ phi_{Y}(t) = e^{i t b } phi_{a X}(t) $$ . For random variables $X$ and $Y$, define the join characteristic function of $X$, and $Y$ by $ phi_{X, Y}(s,t) = mathbb{E}[e^{i s X} e^{i t Y}]$. Then $X$ and $Y$ are independent iff | $$ phi_{X, Y}(s,t) = phi_X(s) phi_Y(t) text{ for all } s, t in mathbb{R} $$ . See chapter 5 of (Grimmett &amp; Stirzaker, 2001) for the statement and proof of the above facts. . Examples of characteristic functions . If $X sim operatorname{Ber}(p)$ then . $$ phi(t) = 1 - p + p e^{i t} $$ . If $X sim operatorname{Bin}(n,p)$ then . $$ phi(t) = (1 - p + p e^{i t} )^n $$ . If $X sim operatorname{NegBin}(r,p)$ then . $$ phi(t) = left ( frac{p}{1 - e^{it} + p e^{i t}} right )^r $$ . If $X sim operatorname{Gam}( alpha, beta)$ then . $$ phi(t) = left ( frac{ beta}{ beta - i t} right )^ alpha $$ . If $X sim operatorname{Exp}( lambda)$ then . $$ phi(t) = frac{ lambda}{ lambda - i t} $$ . If $X sim operatorname{Poi}( mu)$ then . $$ phi(t) = e^{ mu ( e^{i t} - 1)}$$ . If $X sim operatorname{N}( mu, sigma)$ then . $$ phi(t) = exp( i mu t - frac{ sigma t^2}{2}) $$ . If $X sim U(a, b)$ (continuous Uniform random variable) then . $$ phi(t) = frac{e^{i t b} - e^{i t a}}{ i t (b - a)} $$ . See section 5.8 in (Grimmett &amp; Stirzaker, 2001) for more details. Those functions, plus the above facts about characteristic functions, and the following . $$ operatorname{var}[X] = mathbb{E}[X^2] - ( mathbb{E}[X])^2 $$ . can be used to calculate $ mathbb{E}[X]$ and $ operatorname{var}[X]$. . The above formulas also clearly show which distributions are closed under taking sums of independent copies. . Normal distribution, weak law of large numbers, and the central limit theorem . We&#39;ll now study the normal distribution as the error distribution in the central limit theorem. . First recall that the normal distribution has the probability distribution: . $$ f(x) = frac{1}{ sigma sqrt{2 pi} } e^{- frac{1}{2} left ( frac{x- mu}{ sigma} right)^2}$$ . where $ mu in mathbb{R}$ and $ sigma &gt; 0$, and the standard moments are . $$ mathbb{E}[X] = mu, : : mathbb{E}[(X - mathbb{E}[X] )^2] = sigma$$ $$ operatorname{mode}{X} = mu $$ . Now consider a sequence $X_1$, $X_2$, ... of independent and identically distributed random variables each with mean $ mu$ and standard deviation $ sigma$ (good examples being the Bernoulli and Exponential distributions). Let $S_n = X_1 + X_2 + dots + X_n$ be their partial sums, then the weak law of large numbers1 says that $ frac{S_n}{n}$ converges to $ mu$ in distribution as $n$ approaches $ infty$ (see section 5.10 in (Grimmett &amp; Stirzaker, 2001)). We&#39;ll illustrate this theorem by way of example below. . lam = 0.5 mu = 2 def draw(n): return np.random.exponential(mu, size=n) . Below we&#39;ll plot the distribution of $ frac{S_n}{n}$ for $n = 1, 100$ and $1000$ to see the weak law in action. . fig = plt.figure(figsize=(10,10)) n = 1 y = np.array([ sum(draw(n))/n for i in range(1000) ] ) ax = fig.add_subplot(221) ax.hist(y, label=f&#39;mean = {y.mean(): 0.3f}&#39;) ax.title.set_text(&quot;Distribution of a random variable&quot;) n = 100 y = np.array([ sum(draw(n))/n for i in range(1000) ] ) ax = fig.add_subplot(222) ax.hist(y, label=f&#39;mean = {y.mean(): 0.3f}&#39;) ax.title.set_text(f&quot;Average of {n} IID random variables&quot;) n = 1000 y = np.array([ sum(draw(n))/n for i in range(1000) ] ) ax = fig.add_subplot(223) ax.hist(y, label=f&#39;mean = {y.mean(): 0.3f}&#39;) ax.title.set_text(f&quot;Average of {n} IID random variables&quot;) fig.suptitle(&#39;Illustration of the Weak Law of Large Numbers&#39;) plt.show() . It clearly looks like the errors in $ frac{S_n}{n} - mu$ are approaching a normal distribution, in fact $(S_n - n mu)/ sqrt{n sigma^2}$ approaches $N(0,1)$ in distribution as $n$ approaches $ infty$ (provided the $X_i$s has finite non-zero variance, (Grimmett &amp; Stirzaker, 2001)). This fact is the famous central limit theorem, which we&#39;ll illustrate below. . fig = plt.figure(figsize=(10,10)) n = 1 y = np.array([ sum(draw(n))/n for i in range(1000) ] ) ax = fig.add_subplot(221) ax.hist(y, label=f&#39;mean = {y.mean(): 0.3f}&#39;) ax.title.set_text(&quot;Distribution of a random variable&quot;) n = 100 y = np.array([ (sum(draw(n)) - mu * n)/np.sqrt(n) for i in range(1000) ] ) ax = fig.add_subplot(222) ax.hist(y, label=f&#39;mean = {y.mean(): 0.3f}&#39;) ax.title.set_text(f&quot;Errors of {n} IID random variables&quot;) n = 1000 y = np.array([ (sum(draw(n)) - mu * n)/np.sqrt(n) for i in range(1000) ] ) ax = fig.add_subplot(223) ax.hist(y, label=f&#39;mean = {y.mean(): 0.3f}&#39;) ax.title.set_text(f&quot;Errors of {n} IID random variables&quot;) fig.suptitle(&#39;Illustration of the Central Limit Theorem&#39;) plt.show() . Note that it&#39;s straightforward to check that . $$ mathbb{E}[(S_n - n mu)/ sqrt{n sigma^2}] = 0, : : operatorname{var}[(S_n - n mu)/ sqrt{n sigma^2}] = 1$$ . for all $ n &gt; 0 $. So the first two moments of $(S_n - n mu)/ sqrt{n sigma^2}$ agree with the first two moments of $N(0, 1)$. The central limit theorem then says that in the limit of large $n$, all moments of $(S_n - n mu)/ sqrt{n sigma^2}$ agree with all moments of $N(0, 1)$. . Observe that these theorems naturally apply to the Bernoulli and Exponential distributions in the limit of large $n$, showing that after setting the mean to zero and scaling by the standard deviation, they both converge to the standard normal distribution. . Finally, note that the weak law of large numbers, and the central limit theorem can be proven fairly elegantly using charactierstic functions (see (Grimmett &amp; Stirzaker, 2001), for example). Also see chapter 15 in Introduction to probability at an advanced level for more applications of the central limit theorem. . More summaries of standard statistics can be found in stats cookbook. . 1. The strong law of large numbers refers to almost everywhere convergence of the random variables.↩ . Murphy, K. P. (2012). Machine learning - a probabilistic perspective. | Grimmett, G. R., &amp; Stirzaker, D. R. (2001). Probability and random processes. | .",
            "url": "https://krishanr.github.io/fastpages/statistics/2022/01/13/standard-probability-distributions.html",
            "relUrl": "/statistics/2022/01/13/standard-probability-distributions.html",
            "date": " • Jan 13, 2022"
        }
        
    
  

  
  

  
      ,"page1": {
          "title": "About",
          "content": ". My name is Krishan Rajaratnam and I’m data scientist and mathematician. I’ve always had a strong interest in mathematics, science, and technology, and I’m able to combine many of these interests in a career applying machine learning. . I finished my PhD at the University of Toronto under Professor Israel Michael Sigal studying the mathematical theory behind the Fractional Quantum Hall Effect (thesis available here). I also did a Master’s thesis at the University of Waterloo under Professor Dong Eui Chang and Professor Raymond G. McLenaghan studying and developing the mathematical theory behind the orthogonal separation of the Hamilton-Jacobi equation on spaces of constant curvature (thesis available here). . Besides my technical interests, I generally have a growth mindset and am interested in staying fit, with hobbies like biking, running, and weight lifting as well as photography. . This website is powered by fastpages 1. . a blogging platform that natively supports Jupyter notebooks in addition to other formats. &#8617; . |",
          "url": "https://krishanr.github.io/fastpages/about/",
          "relUrl": "/about/",
          "date": ""
      }
      
  

  

  
  

  

  
  

  

  
  

  
  

  
      ,"page9": {
          "title": "",
          "content": "Sitemap: {{ “sitemap.xml” | absolute_url }} | .",
          "url": "https://krishanr.github.io/fastpages/robots.txt",
          "relUrl": "/robots.txt",
          "date": ""
      }
      
  

  
  

}