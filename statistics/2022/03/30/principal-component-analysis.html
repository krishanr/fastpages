<!DOCTYPE html>
<html lang="en"><head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="twitter:card" content="summary_large_image" /><!-- Begin Jekyll SEO tag v2.7.1 -->
<title>Principal component analysis | Krishan Rajaratnam’s blog</title>
<meta name="generator" content="Jekyll v4.1.1" />
<meta property="og:title" content="Principal component analysis" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="An expository article on principal componenent analysis (PCA), starting from the theory of random vectors and then gradually moving on to concrete implementation using numpy, and scikit-learn." />
<meta property="og:description" content="An expository article on principal componenent analysis (PCA), starting from the theory of random vectors and then gradually moving on to concrete implementation using numpy, and scikit-learn." />
<link rel="canonical" href="https://krishanr.github.io/fastpages/statistics/2022/03/30/principal-component-analysis.html" />
<meta property="og:url" content="https://krishanr.github.io/fastpages/statistics/2022/03/30/principal-component-analysis.html" />
<meta property="og:site_name" content="Krishan Rajaratnam’s blog" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2022-03-30T00:00:00-05:00" />
<meta name="twitter:card" content="summary" />
<meta property="twitter:title" content="Principal component analysis" />
<script type="application/ld+json">
{"mainEntityOfPage":{"@type":"WebPage","@id":"https://krishanr.github.io/fastpages/statistics/2022/03/30/principal-component-analysis.html"},"url":"https://krishanr.github.io/fastpages/statistics/2022/03/30/principal-component-analysis.html","@type":"BlogPosting","headline":"Principal component analysis","dateModified":"2022-03-30T00:00:00-05:00","datePublished":"2022-03-30T00:00:00-05:00","description":"An expository article on principal componenent analysis (PCA), starting from the theory of random vectors and then gradually moving on to concrete implementation using numpy, and scikit-learn.","@context":"https://schema.org"}</script>
<!-- End Jekyll SEO tag -->
<link rel="stylesheet" href="/fastpages/assets/css/style.css"><link type="application/atom+xml" rel="alternate" href="https://krishanr.github.io/fastpages/feed.xml" title="Krishan Rajaratnam's blog" /><link rel="icon" href="/fastpages/images/favicon.svg"><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/Primer/15.2.0/primer.css" integrity="sha512-xTz2ys4coGAOz8vuV1NcQBkgVmKhsSEtjbqyMJbBHRplFuvKIUo6xhLHpAyPt9mfR6twHJgn9OgVLuqOvjeBhg==" crossorigin="anonymous" />
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.14.0/css/all.min.css" integrity="sha512-1PKOgIY59xJ8Co8+NE6FZ+LOAZKjy+KY8iq0G4B3CyeY6wYHN3yt9PW0XpSriVlkMXe40PTKnXrLnZ9+fkDaog==" crossorigin="anonymous" />
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.12.0/katex.min.css" integrity="sha512-h7nl+xz8wgDlNM4NqKEM4F1NkIRS17M9+uJwIGwuo8vGqIl4BhuCKdxjWEINm+xyrUjNCnK5dCrhM0sj+wTIXw==" crossorigin="anonymous" />
    <script src="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.12.0/katex.min.js" integrity="sha512-/CMIhXiDA3m2c9kzRyd97MTb3MC6OVnx4TElQ7fkkoRghwDf6gi41gaT1PwF270W6+J60uTmwgeRpNpJdRV6sg==" crossorigin="anonymous"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.12.0/contrib/auto-render.min.js" integrity="sha512-Do7uJAaHZm5OLrIv/yN4w0iG1dbu01kzdMNnFfu/mAqgUk6Nniv2JYHcwH+cNwjqgLcqcuBBk+JRvprLVI8azg==" crossorigin="anonymous"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js" integrity="sha512-0doc9hKxR3PYwso42RD1p5ySZpzzuDiOwMrdCEh2WdJZCjcmFKc/wEnL+z8fBQrnHoiNWbo+3fiGkOYXBdQp4A==" crossorigin="anonymous"></script>
    <script>
    document.addEventListener("DOMContentLoaded", function() {
        renderMathInElement( document.body, {
        delimiters: [
            {left: "$$", right: "$$", display: true},
            {left: "[%", right: "%]", display: true},
            {left: "$", right: "$", display: false}
        ]}
        );
    });
    </script>


<script>
function wrap_img(fn) {
    if (document.attachEvent ? document.readyState === "complete" : document.readyState !== "loading") {
        var elements = document.querySelectorAll(".post img");
        Array.prototype.forEach.call(elements, function(el, i) {
            if (el.getAttribute("title") && (el.className != "emoji")) {
                const caption = document.createElement('figcaption');
                var node = document.createTextNode(el.getAttribute("title"));
                caption.appendChild(node);
                const wrapper = document.createElement('figure');
                wrapper.className = 'image';
                el.parentNode.insertBefore(wrapper, el);
                el.parentNode.removeChild(el);
                wrapper.appendChild(el);
                wrapper.appendChild(caption);
            }
        });
    } else { document.addEventListener('DOMContentLoaded', fn); }
}
window.onload = wrap_img;
</script>

<script>
    document.addEventListener("DOMContentLoaded", function(){
    // add link icon to anchor tags
    var elem = document.querySelectorAll(".anchor-link")
    elem.forEach(e => (e.innerHTML = '<i class="fas fa-link fa-xs"></i>'));
    });
</script>
</head>
<body><header class="site-header">

  <div class="wrapper"><a class="site-title" rel="author" href="/fastpages/">Krishan Rajaratnam&#39;s blog</a><nav class="site-nav">
        <input type="checkbox" id="nav-trigger" class="nav-trigger" />
        <label for="nav-trigger">
          <span class="menu-icon">
            <svg viewBox="0 0 18 15" width="18px" height="15px">
              <path d="M18,1.484c0,0.82-0.665,1.484-1.484,1.484H1.484C0.665,2.969,0,2.304,0,1.484l0,0C0,0.665,0.665,0,1.484,0 h15.032C17.335,0,18,0.665,18,1.484L18,1.484z M18,7.516C18,8.335,17.335,9,16.516,9H1.484C0.665,9,0,8.335,0,7.516l0,0 c0-0.82,0.665-1.484,1.484-1.484h15.032C17.335,6.031,18,6.696,18,7.516L18,7.516z M18,13.516C18,14.335,17.335,15,16.516,15H1.484 C0.665,15,0,14.335,0,13.516l0,0c0-0.82,0.665-1.483,1.484-1.483h15.032C17.335,12.031,18,12.695,18,13.516L18,13.516z"/>
            </svg>
          </span>
        </label>

        <div class="trigger"><a class="page-link" href="/fastpages/about/">About</a><a class="page-link" href="/fastpages/search/">Search</a><a class="page-link" href="/fastpages/categories/">Tags</a></div>
      </nav></div>
</header>
<main class="page-content" aria-label="Content">
      <div class="wrapper">
        <article class="post h-entry" itemscope itemtype="http://schema.org/BlogPosting">

  <header class="post-header">
    <h1 class="post-title p-name" itemprop="name headline">Principal component analysis</h1><p class="page-description">An expository article on principal componenent analysis (PCA), starting from the theory of random vectors and then gradually moving on to concrete implementation using numpy, and scikit-learn.</p><p class="post-meta post-meta-title"><time class="dt-published" datetime="2022-03-30T00:00:00-05:00" itemprop="datePublished">
        Mar 30, 2022
      </time>
       • <span class="read-time" title="Estimated read time">
    
    
      16 min read
    
</span></p>

    
      <p class="category-tags"><i class="fas fa-tags category-tags-icon"></i></i> 
      
        <a class="category-tags-link" href="/fastpages/categories/#statistics">statistics</a>
        
      
      </p>
    

    
      
        <div class="pb-5 d-flex flex-justify-center">
          <div class="px-2">

    <a href="https://github.com/krishanr/fastpages/tree/master/_notebooks/2022-03-30-principal-component-analysis.ipynb" role="button" target="_blank">
<img class="notebook-badge-image" src="/fastpages/assets/badges/github.svg" alt="View On GitHub">
    </a>
</div>

          
          <div class="px-2">
    <a href="https://colab.research.google.com/github/krishanr/fastpages/blob/master/_notebooks/2022-03-30-principal-component-analysis.ipynb" target="_blank">
        <img class="notebook-badge-image" src="/fastpages/assets/badges/colab.svg" alt="Open In Colab"/>
    </a>
</div>
          
        </div>
      </header>

  <div class="post-content e-content" itemprop="articleBody">
    <ul id="toc" class="section-nav">
<li class="toc-entry toc-h2"><a href="#Transformations-of-random-vectors">Transformations of random vectors </a></li>
<li class="toc-entry toc-h2"><a href="#Population-PCA">Population PCA </a>
<ul>
<li class="toc-entry toc-h3"><a href="#Population-PCA-using-the-correlation-matrix">Population PCA using the correlation matrix </a></li>
</ul>
</li>
<li class="toc-entry toc-h2"><a href="#Sample-PCA">Sample PCA </a>
<ul>
<li class="toc-entry toc-h4"><a href="#Reconstruction-error">Reconstruction error </a></li>
</ul>
</li>
<li class="toc-entry toc-h2"><a href="#Large-sample-properties">Large sample properties </a></li>
<li class="toc-entry toc-h2"><a href="#Practical-considerations">Practical considerations </a>
<ul>
<li class="toc-entry toc-h3"><a href="#PCA-using-SVD-directly">PCA using SVD directly </a></li>
<li class="toc-entry toc-h3"><a href="#PCA-using-scikit-learn">PCA using scikit-learn </a>
<ul>
<li class="toc-entry toc-h4"><a href="#Computational-complexity">Computational complexity </a></li>
</ul>
</li>
</ul>
</li>
</ul><!--
#################################################
### THIS FILE WAS AUTOGENERATED! DO NOT EDIT! ###
#################################################
# file to edit: _notebooks/2022-03-30-principal-component-analysis.ipynb
-->

<div class="container" id="notebook-container">
        
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Principal component analysis (PCA) is a well known technique for dimensionality reduction, dating back over one hundred years. Here we'll summarize the theory and application of PCA, showing for example that it's most naturally applicable to multivariate normal data, which is determined by its first two moments. We shall derive PCA as a canonical form for random vectors, obtained using the population covariance matrix for a population or the sample covariance matrix for a sample. We'll also see how this decomposition differs when using the population correlation matrix or the sample correlation matrix instead. We conclude with a computation of PCA for the iris dataset, first from scratch using numpy, and then using the scikit-learn API.</p>
<p>We follow chapter 8 in <a class="citation" href="#Johnson1982AppliedMS">(Johnson &amp; Wichern, 1982)</a> for the theory of PCA, both in terms of populations of random variables and samples of random variables, and then apply it following chapter 8 in <a class="citation" href="#Gron2017HandsOnML">(Géron, 2017)</a>. We also follow Professor Helwig's notes available <a href="http://users.stat.umn.edu/~helwig/notes/pca-Notes.pdf">here</a>.</p>
<p>By making a distinction between population and sample PCA, we can make statements about limits of the sample PCA as the sample size goes to infinity. Besides theoretical interest, these limits are useful for calculating confidence intervals, p-values, etc.</p>
<p>Note hereafter that all vectors are assumed to row vectors unless specified otherwise, and we'll use $\vec{1}$ to denote the row vector with components all equal to $1$. We'll also make the following definitions. Let $\vec{X} = (X_1, ..., X_p)$ be a random (row) vector. The vector has (population) mean $\vec{\mu} = \mathbb{E}[\vec{X}]$ and (population) covariance matrix $\Sigma = \mathbb{E}[(\vec{X} - \vec{\mu})^T(\vec{X} - \vec{\mu})] $. The (population) correlation matrix is</p>
$$
P = \begin{bmatrix}
    1       &amp; \rho_{12} &amp; \rho_{13} &amp; \dots &amp; \rho_{1p} \\
    \rho_{21}       &amp; 1 &amp; \rho_{23} &amp; \dots &amp; \rho_{2p} \\
    \vdots &amp; \vdots &amp; \vdots &amp; \ddots &amp; \vdots \\
    \rho_{p1}       &amp; \rho_{p2} &amp; \rho_{p3} &amp; \dots &amp; 1
\end{bmatrix}
$$<p>where</p>
$$
\begin{aligned}
\rho_{jk} &amp; = \frac{\sigma_{jk}}{\sqrt{ \sigma_{jj} \sigma_{kk} }}, &amp; \sigma_{jk} &amp; = \Sigma_{jk}
\end{aligned}
$$<p>is the Pearson correlation coefficient between variables $X_j$ and $X_k$.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Transformations-of-random-vectors">
<a class="anchor" href="#Transformations-of-random-vectors" aria-hidden="true"><span class="octicon octicon-link"></span></a>Transformations of random vectors<a class="anchor-link" href="#Transformations-of-random-vectors"> </a>
</h2>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>For $\vec{v}, \vec{u} \in \mathbb{R}^p$, let $Y = \vec{X} \vec{v}^T = \vec{X} \cdot \vec{v}$ and $Z = \vec{X} \cdot \vec{u}$, then one can show that</p>
$$
\begin{aligned}
\mathbb{E}[Y] &amp; = \vec{\mu} \cdot \vec{v} \\
\operatorname{cov}[Y, Z] &amp; = \vec{v} \: \Sigma \: \vec{u}^T
\end{aligned}
$$<p>More generally, with $v_1,\dotsc,v_q \in \mathbb{R}^p$ and $c \in \mathbb{R}^q$, let $Y = \vec{X} \cdot \vec{v_i}$, and define the $q \times p$ matrix $V$ by:</p>
$$
V = \begin{bmatrix}
\vec{v}_1 \\
\vdots \\
\vec{v}_q \\
\end{bmatrix}
$$<p>so that $\vec{Y} = \vec{X} \cdot V^T$, then</p>
$$
\begin{aligned}
\mathbb{E}[\vec{Y} + c] &amp; = \vec{\mu} \cdot V^T + c \\
\operatorname{cov}[\vec{Y} + c ] &amp; = \operatorname{cov}[\vec{X} \cdot V^T] = V \; \Sigma_X \; V^T
\end{aligned}
$$<p>Also note that</p>
<p>
$$ \sum_{j=1}^q \operatorname{Var}(Y_j)  = \operatorname{tr}(\operatorname{cov}[\vec{Y}]) = \operatorname{tr}(V \; \Sigma_X \; V^T) = \operatorname{tr}( \Sigma_X \; V^T V) $$
</p>
<p>by the cyclic property of the trace. Hence when $q = p$ and $V$ is orthonormal,</p>
<p>
$$ \sum_{j=1}^p \operatorname{Var}(Y_j)  = \operatorname{tr}(\operatorname{cov}[\vec{Y}]) = \operatorname{tr}(A \; \Sigma_X \; A^T) = \operatorname{tr}( \Sigma_X ) = \sum_{j=1}^p \operatorname{Var}(X_j) $$
</p>
<p><strong>Spectral theorem for symmetric matricies</strong></p>
<p>Recall for any $p \times p$ symmetric matrix $\Sigma$, if we let $\lambda_1 \geq \lambda_2 \geq \dots \geq \lambda_p \geq 0$ be the eigenvalues of $\Sigma$, then</p>
$$ 
    \begin{aligned}
        \lambda_1 &amp; = \operatorname{max}_{x \neq 0} \frac{\vec{x} \: \Sigma \: \vec{x}^T}{\lVert x \rVert^2} \\
        \lambda_p &amp; = \operatorname{min}_{x \neq 0} \frac{\vec{x} \: \Sigma \: \vec{x}^T}{\lVert x \rVert^2} \\
        \frac{\lambda_1}{\lambda_p} &amp; = \kappa(\Sigma) = \operatorname{max}_{x , y \neq 0} \frac{\vec{x} \: \Sigma \: \vec{x}^T}{\lVert x \rVert^2} \frac{\lVert x \rVert^2}{\vec{y} \: \Sigma \: \vec{y}^T}
    \end{aligned}
$$<p>where $\kappa(\Sigma)$ is the condition number of $\Sigma$, defined when $\Sigma$ is positive definite. There are also similar formulas for the other eigenvalues defined on appropriate subspaces.</p>
<p>Finally, since the covariance matrix $\Sigma$ is positive semi-definite, the spectral theorem applies to it, which we shall review later. This together with the fact that any random variable with zero variance is zero implies that $\Sigma$ is positive definite iff the random variables $X_1, ..., X_p$ are linearly independent.</p>
<p><strong>Two dimensions</strong></p>
<p>Here's a useful corollary of the above transformation law for the covariance matrix. Suppose $X_1$ and $X_2$ are random variables with covariance matrix $\Sigma_X$. Then the variables $Y_1$ and $Y_2$ defined by</p>
$$
    \begin{aligned}
        Y_1 &amp; = X_1 - X_2  \\
        Y_2 &amp; = X_1 + X_2
    \end{aligned}
$$<p>have covariance</p>
$$
    \Sigma_Y = \operatorname{cov}[\vec{Y}] = \begin{bmatrix}
    \sigma_{11} - 2 \sigma_{12} + \sigma_{22}        &amp; \sigma_{11} - \sigma_{22} \\
    \sigma_{11} - \sigma_{22}        &amp; \sigma_{11} + 2 \sigma_{12} + \sigma_{22}
\end{bmatrix}
$$<p>Thus $Y_1$ and $Y_2$ are uncorrelated iff $X_1$ and $X_2$ have the same variance, i.e. $\sigma_{11} = \sigma_{22}$.</p>
<p>Moreover if $X_1$ and $X_2$ are independent, then $Y_1$ and $Y_2$ are in general not independent. In fact, if $Y_1$ and $Y_2$ are also independent, then $X_1$ and $X_2$ are normal random variables (see <a href="https://math.stackexchange.com/questions/42115/when-linear-combinations-of-independent-random-variables-are-still-independent">here</a>). This fact is known as <em>Bernstein's theorem</em>, and holds for more general linear combinations.</p>
<p>Thus a unitary transformation of iid random variables have the same covariance matrix but are not in general independent.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Population-PCA">
<a class="anchor" href="#Population-PCA" aria-hidden="true"><span class="octicon octicon-link"></span></a>Population PCA<a class="anchor-link" href="#Population-PCA"> </a>
</h2>
<p>As above let $\vec{Y} = \vec{X} \cdot V^T$ where $V$ is a $pxp$ matrix. Then the formula</p>
<p>
$$ \Sigma_Y = \operatorname{cov}[\vec{Y}] = V \; \Sigma_X \; V^T $$
</p>
<p>shows that $\Sigma_Y$ and $\Sigma_X$ are similar quadratic forms. Thus since $\Sigma_X$ is symmetric, by the spectral theorem there exists a new set of random variables $Y_1, \dotsc, Y_p$ in which $\Sigma_Y$ is diagonal. These are the <em>principal components</em> of the random vector $\vec{X}$, which can also be defined using notations from probability theory as follows:</p>
$$
\begin{aligned}
    \text{First principal component }  = Y_1  = &amp; \text{ linear combination of } \vec{X}\vec{v}_1^T \text{ that maximizes } \\
     &amp; \operatorname{Var}[\vec{X}\vec{v}_1^T] \text{ subject to } \lVert \vec{v}_1 \rVert = 1 \\
     \text{Second principal component }  = Y_2  = &amp; \text{ linear combination of } \vec{X}\vec{v}_2^T \text{ that maximizes } \\
     &amp; \operatorname{Var}[\vec{X}\vec{v}_2^T] \text{ subject to } \lVert \vec{v}_2 \rVert = 1 \text{ and } \vec{v_2} \: \Sigma \: \vec{v_1}^T = \operatorname{Cov}[\vec{X}\vec{v}_1^T, \vec{X}\vec{v}_2^T] = 0 \\
     &amp; \vdots \\
     \text{Last principal component }  = Y_p  = &amp; \text{ linear combination of } \vec{X}\vec{v}_p^T \text{ that maximizes } \\
     &amp; \operatorname{Var}[\vec{X}\vec{v}_p^T] \text{ subject to } \lVert \vec{v}_p \rVert = 1 \text{ and } \operatorname{Cov}[\vec{X}\vec{v}_p^T, \vec{X}\vec{v}_1^T] = \operatorname{Cov}[\vec{X}\vec{v}_p^T, \vec{X}\vec{v}_2^T] = \dots = \operatorname{Cov}[\vec{X}\vec{v}_p^T, \vec{X}\vec{v}_{p-1}^T] = 0
\end{aligned}
$$<p>Equivalently, let $(\lambda_1, \vec{e}_1)$, $(\lambda_2, \vec{e}_2)$, ..., $(\lambda_p, \vec{e}_p)$ be the eigenvalue-eigenvector pairs of $\Sigma$ with the eigenvalues ordered in non-increasing order. Then the ith principal component is:</p>
$$
Y_i = \vec{X}\vec{e}_i^T \quad, i = 1,...,p
$$<p>with</p>
$$
\begin{aligned}
\operatorname{Var}[Y_i]  &amp; = \lambda_i \quad i = 1,...,p \\
\operatorname{Cov}[Y_i, Y_j]  &amp; = 0 \quad i \neq j
\end{aligned}
$$<p>Thus the ith maximal variance of $\Sigma$ is the ith eigenvalue of $\Sigma$.</p>
<p>Also note that only unique eigenvalues have unique eigenvectors (up to sign), so the principal components are in general not unique.</p>
<p>The above formula for the trace implies that the random variables $Y_1, ..., Y_p$ have the same total variance as $X_1, ..., X_p$, since</p>
<p>
$$ \sum_{j=1}^p \operatorname{Var}(X_j)  = \operatorname{tr}(\Sigma) = \operatorname{tr}(V \; \Sigma_X \; V^T ) = \operatorname{tr}(\Sigma_X) = \sum_{j=1}^p \operatorname{Var}(Y_j) = \sum_{j=1}^p \lambda_j $$
</p>
<p>Thus we can define the proportion of variance captured by the $k$th principal component as</p>
$$
\begin{aligned}
&amp; \text{Proporition of variance due }  = \frac{\lambda_k}{\sum_{j=1}^p \lambda_j}, \quad k= 1,...,p \\
&amp; \text{to the $k$th principal component }
\end{aligned}
$$<p>The basic idea behind PCA for dimensionality reduction is to only keep the the first $k$ principal components which captures, say $90\%$, of the variance, thereby reducing the number of variables.</p>
<p>Another way to select the principal components is to choose the most variables possible such that the conditon number (ratio of largest to smallest eigenvalues) of the reduced covariance matrix is close to $1$. This is because machine learning algorithms, like linear and logistic regression, preform better (more precision and faster convergence for gradient based methods) when the condition number of the covariance matrix is close to $1$.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Population-PCA-using-the-correlation-matrix">
<a class="anchor" href="#Population-PCA-using-the-correlation-matrix" aria-hidden="true"><span class="octicon octicon-link"></span></a>Population PCA using the correlation matrix<a class="anchor-link" href="#Population-PCA-using-the-correlation-matrix"> </a>
</h3>
<p>PCA can also be calculated using the correlation matrix $P$ which is the covariance matrix of the standardized features having their mean set to $0$ and variance to $1$. Specifically, one applies the above calculations to the following variables:</p>
$$
\begin{aligned}
    Z_1 &amp;= \frac{X_1 - \mu_1}{\sqrt{\sigma_{11}}} \\
    Z_2 &amp;= \frac{X_2 - \mu_2}{\sqrt{\sigma_{22}}} \\
    \vdots &amp; \quad \vdots \\
    Z_p &amp;= \frac{X_p - \mu_p}{\sqrt{\sigma_{pp}}}
\end{aligned}
$$<p>In matrix notation we have</p>
$$
\begin{aligned}
\vec{Z} &amp;= (\vec{W}^{\frac{1}{2}})^{-1}(\vec{X} - \vec{\mu}) \\
\operatorname{cov}[\vec{Z}] &amp; = (\vec{W}^{\frac{1}{2}})^{-1} \; \Sigma \; (\vec{W}^{\frac{1}{2}})^{-1} = P
\end{aligned}
$$<p>where $\vec{W} = \operatorname{diag}(\sigma_{11},...,\sigma_{pp})$. Then one obtains a decomposition similar to above with the following difference in the formula:</p>
$$
\sum_{j=1}^p \operatorname{Var}(Y_j) = \sum_{j=1}^p \operatorname{Var}(X_j) = p
$$<p>Then the formula for the proportion of variance captured by the $k$th principal component simplifies to:</p>
$$
\begin{aligned}
&amp; \text{Proporition of variance due }  = \frac{\lambda_k}{p}, \quad k= 1,...,p \\
&amp; \text{to the $k$th principal component }
\end{aligned}
$$<p>It's important to note that the principal components calculated from $\Sigma$ and $P$ can differ significantly, being a different linear combination of the original variables (Example 8.2 in <a class="citation" href="#Johnson1982AppliedMS">(Johnson &amp; Wichern, 1982)</a>). The principal components are similar when the variances for the $p$ random variables are the same, $\sigma = \sigma_{11} = \sigma_{22} = \dots = \sigma_{pp}$. Finally note that it's <strong>good practise to work with variables on the same scales</strong> so that the principal components aren't heavily skewed towards the larger variables.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Sample-PCA">
<a class="anchor" href="#Sample-PCA" aria-hidden="true"><span class="octicon octicon-link"></span></a>Sample PCA<a class="anchor-link" href="#Sample-PCA"> </a>
</h2>
<p>Consider $n$ iid realizations $\vec{X}_1, ..., \vec{X}_n$ from the random vector $\vec{X}$. We can arrange this data into a feature matrix</p>
$$ 
X =  \begin{bmatrix}
\vec{X}_1 \\
\vdots \\
\vec{X}_n \\
\end{bmatrix}
$$<p>The sample covariance matrix, $S$, is:</p>
$$ 
\begin{aligned}
S_{i j}  = \frac{1}{n-1} \sum_{k=1}^n (X_{k i} - \bar{X}_i) (X_{k j} - \bar{X}_j) = \frac{1}{n-1} (X - \vec{1} \otimes\bar{X})^T (X - \bar{X} \otimes \vec{1}) 
\end{aligned} \quad \quad i= 1,...,p \text{ and } j = 1,...,p$$<p>and the sample correlation matrix, $R$, is:</p>
$$
\begin{aligned}
R_{ij} = \frac{S_{ij}}{\sqrt{S_{ii}} \sqrt{S_{jj}}} = \frac{\sum_{k=1}^n (X_{k i} - \bar{X}_i) (X_{k j} - \bar{X}_j)}{\sqrt{\sum_{k=1}^n (X_{k i} - \bar{X}_i)^2 } \sqrt{\sum_{k=1}^n (X_{k j} - \bar{X}_j)^2}}
\end{aligned} \quad \quad i= 1,...,p \text{ and } j = 1,...,p
$$<p>For $\vec{v} \in \mathbb{R}^p$ a new feature is defined by the equation</p>
<p>
$$ Y = \vec{X} \cdot \vec{v} $$
</p>
<p>Formulas similar to above show that the sample covariance matrix transforms according to (see chapter 8 in <a class="citation" href="#Johnson1982AppliedMS">(Johnson &amp; Wichern, 1982)</a>):</p>
<p>
$$ S_Y = V S_X V^T $$
</p>
<p>Thus an identical construction can be given for the principal components, now using $S$ in place of $\Sigma$, or $R$ in place of $P$.</p>
<h4 id="Reconstruction-error">
<a class="anchor" href="#Reconstruction-error" aria-hidden="true"><span class="octicon octicon-link"></span></a>Reconstruction error<a class="anchor-link" href="#Reconstruction-error"> </a>
</h4>
<p>Let $W_d = [ v_1 \dots v_d ]$ be the matrix whose columns are the first $d$ eigenvectors of $S_X$ (ordered from largest to smallest eigenvalue). Then given any feature vector $\vec{X}_i$, the vector $\vec{X}_i W_d$ is the $d$ dimensional projection, and the vector $\vec{X}_i W_d W_d^T$ is the reconstructed vector. There's a fairly simple formula for the reconstruction error</p>
$$
\sum_{i=1}^n || \vec{X}_i W_d W_d^T - \vec{X}_i||^2
$$<p>It turns out that (see chapter 9 in <a class="citation" href="#Johnson1982AppliedMS">(Johnson &amp; Wichern, 1982)</a> for a proof)</p>
$$
\begin{aligned}
\sum_{i=1}^n || \vec{X}_i W_d W_d^T - \vec{X}_i||^2 &amp; = \operatorname{tr}[(X W_d W_d^T - X)(X W_d W_d^T - X)^T] \\
&amp;  \vdots \\
&amp; = \lambda_{d+1} + \dots + \lambda_p
\end{aligned}
$$<p>Thus the recontruction error of the $d$ dimensional projection is equal to the remaining $p-d$ eigenvalues of the covariance matrix, i.e. the unexplained variance. Finally, note that this is the smallest possible error among all $d$ dimensional projections, and this is another defining property of PCA.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Large-sample-properties">
<a class="anchor" href="#Large-sample-properties" aria-hidden="true"><span class="octicon octicon-link"></span></a>Large sample properties<a class="anchor-link" href="#Large-sample-properties"> </a>
</h2>
<p>As expected, when the feature matrix $X$ comes from a multivariate Gaussian, the principal components recover the natural frame which diagonalizes the covariance matrix of the Gaussian. In fact, much more can be said.</p>
<p>When $\vec{X}_i \overset{iid}{\sim} N(\vec{\mu}, \vec{\Sigma})$ and the eigenvalues of $\Sigma$ are strictly positive and unique: $\lambda_1 &gt; \dots \lambda_p &gt; 0$, we can describe the large sample properties of the principal directions and eigenvalues. Then as $n \rightarrow \infty$, we have (<a class="citation" href="#Johnson1982AppliedMS">(Johnson &amp; Wichern, 1982)</a>):</p>
$$
    \sqrt{n}(\hat{\vec{\lambda}} - \vec{\lambda}) \approx N(\vec{0}, 2 \vec{\Lambda}^2) \\
    \sqrt{n}(\hat{\vec{v}}_k - \vec{v}_k) \approx N(\vec{0}, \vec{V}_k)
$$<p>where $\Lambda = \operatorname{diag}(\lambda_1, ..., \lambda_k)$ and</p>
$$
    \vec{V}_k = \lambda_k \sum_{l \neq k} \frac{\lambda_l}{(\lambda_l - \lambda_k)^2} \vec{v}_l^T \vec{v}_l
$$<p>Furthermore, as $n \rightarrow \infty$, we have that $\hat{\lambda}_k$ and $\hat{\vec{v}}_k$ are independent.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Practical-considerations">
<a class="anchor" href="#Practical-considerations" aria-hidden="true"><span class="octicon octicon-link"></span></a>Practical considerations<a class="anchor-link" href="#Practical-considerations"> </a>
</h2>
<p>Below we follow <a href="https://github.com/ageron/handson-ml2/blob/master/08_dimensionality_reduction.ipynb">A. Geron's notes on PCA</a> to implement it in numpy and sckit-learn for the iris dataset.</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="kn">from</span> <span class="nn">sklearn</span> <span class="kn">import</span> <span class="n">datasets</span>
<span class="kn">from</span> <span class="nn">sklearn.decomposition</span> <span class="kn">import</span> <span class="n">PCA</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>

<span class="n">iris</span> <span class="o">=</span> <span class="n">datasets</span><span class="o">.</span><span class="n">load_iris</span><span class="p">()</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="n">iris</span><span class="p">[</span><span class="s1">'feature_names'</span><span class="p">])</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>['sepal length (cm)', 'sepal width (cm)', 'petal length (cm)', 'petal width (cm)']
</pre>
</div>
</div>

</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">iris</span><span class="p">[</span><span class="s1">'data'</span><span class="p">],</span> <span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s1">'sepal_length'</span><span class="p">,</span> <span class="s1">'sepal_width'</span><span class="p">,</span> <span class="s1">'petal_length'</span><span class="p">,</span> <span class="s1">'petal_width'</span><span class="p">])</span>
<span class="n">df</span><span class="o">.</span><span class="n">head</span><span class="p">(</span><span class="mi">5</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_html rendered_html output_subarea output_execute_result">
<div>
<style scoped="">
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>sepal_length</th>
      <th>sepal_width</th>
      <th>petal_length</th>
      <th>petal_width</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>5.1</td>
      <td>3.5</td>
      <td>1.4</td>
      <td>0.2</td>
    </tr>
    <tr>
      <th>1</th>
      <td>4.9</td>
      <td>3.0</td>
      <td>1.4</td>
      <td>0.2</td>
    </tr>
    <tr>
      <th>2</th>
      <td>4.7</td>
      <td>3.2</td>
      <td>1.3</td>
      <td>0.2</td>
    </tr>
    <tr>
      <th>3</th>
      <td>4.6</td>
      <td>3.1</td>
      <td>1.5</td>
      <td>0.2</td>
    </tr>
    <tr>
      <th>4</th>
      <td>5.0</td>
      <td>3.6</td>
      <td>1.4</td>
      <td>0.2</td>
    </tr>
  </tbody>
</table>
</div>
</div>

</div>

</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">df</span><span class="o">.</span><span class="n">describe</span><span class="p">()</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_html rendered_html output_subarea output_execute_result">
<div>
<style scoped="">
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>sepal_length</th>
      <th>sepal_width</th>
      <th>petal_length</th>
      <th>petal_width</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>count</th>
      <td>150.000000</td>
      <td>150.000000</td>
      <td>150.000000</td>
      <td>150.000000</td>
    </tr>
    <tr>
      <th>mean</th>
      <td>5.843333</td>
      <td>3.057333</td>
      <td>3.758000</td>
      <td>1.199333</td>
    </tr>
    <tr>
      <th>std</th>
      <td>0.828066</td>
      <td>0.435866</td>
      <td>1.765298</td>
      <td>0.762238</td>
    </tr>
    <tr>
      <th>min</th>
      <td>4.300000</td>
      <td>2.000000</td>
      <td>1.000000</td>
      <td>0.100000</td>
    </tr>
    <tr>
      <th>25%</th>
      <td>5.100000</td>
      <td>2.800000</td>
      <td>1.600000</td>
      <td>0.300000</td>
    </tr>
    <tr>
      <th>50%</th>
      <td>5.800000</td>
      <td>3.000000</td>
      <td>4.350000</td>
      <td>1.300000</td>
    </tr>
    <tr>
      <th>75%</th>
      <td>6.400000</td>
      <td>3.300000</td>
      <td>5.100000</td>
      <td>1.800000</td>
    </tr>
    <tr>
      <th>max</th>
      <td>7.900000</td>
      <td>4.400000</td>
      <td>6.900000</td>
      <td>2.500000</td>
    </tr>
  </tbody>
</table>
</div>
</div>

</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Since the units of each feature are comparable (the standard deviations are of the same order of magnitude), we will calculate PCA using the sample covariance matrix. If on the otherhand, the magnitudes differed by orders of magnitude, we would calculate PCA using the sample correlation matrix.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="PCA-using-SVD-directly">
<a class="anchor" href="#PCA-using-SVD-directly" aria-hidden="true"><span class="octicon octicon-link"></span></a>PCA using SVD directly<a class="anchor-link" href="#PCA-using-SVD-directly"> </a>
</h3>
<p>The principal components can be calculated by diagonalizing the covariance matrix or calulating the singular value decomposition of the feature matrix. We'll use the latter for numerical reasons.</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">X</span> <span class="o">=</span> <span class="n">iris</span><span class="p">[</span><span class="s1">'data'</span><span class="p">]</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>The SVD of $X$ is calculated after subtracting off the sample mean. We'll call this matrix $X_{centered}$ and work with it hereafter. Then the SVD of $X_{centered}$ is</p>
<p>$X_{centered} = U D V^T$</p>
<p>where $U$ is an $n \times n$ orthonormal matrix, $V$ is an $m \times m$ orthonormal matrix, and $D = \operatorname{diag}(d_{11}, ..., d_{mm})$ is an $n \times m$ rectangular diagonal matrix.</p>
<p>The matrix $V$ is the matrix of eigenvectors from the sample PCA above, and the diagonal covariance matrix $S_Y$ is obtained by squaring the singular values and dividing by $n-1$:</p>
$$
S_Y =   \frac{1}{n-1}\begin{bmatrix}
    d_{11}^2 &amp; &amp; \\
    &amp; \ddots &amp; \\
    &amp; &amp; d_{mm}^2
  \end{bmatrix}
$$<p>For this example, we have:</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">X_centered</span> <span class="o">=</span> <span class="n">X</span> <span class="o">-</span> <span class="n">X</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="n">U</span><span class="p">,</span> <span class="n">D</span><span class="p">,</span> <span class="n">Vt</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">svd</span><span class="p">(</span><span class="n">X_centered</span><span class="p">)</span>
<span class="n">V</span> <span class="o">=</span> <span class="n">Vt</span><span class="o">.</span><span class="n">T</span>
<span class="n">eigs</span> <span class="o">=</span> <span class="n">D</span> <span class="o">**</span> <span class="mi">2</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>The $d$-dimensional projection can be calcualted using the $p \times d$ matrix $W_d$ whose $d$ columns are the first $d$ eigenvectors.</p>
<p>$X_{d-proj} = X_{centered}    W_d$</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">W2</span> <span class="o">=</span> <span class="n">V</span><span class="p">[:,</span> <span class="p">:</span><span class="mi">2</span><span class="p">]</span>
<span class="c1"># W2 can also be obtained from the sklearn package using: pca.components_.T </span>
<span class="n">X2D_diy</span> <span class="o">=</span> <span class="n">X_centered</span> <span class="o">@</span> <span class="n">W2</span>
<span class="n">X2D_diy</span><span class="o">.</span><span class="n">shape</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>(150, 2)</pre>
</div>

</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Obtain the reconstructed data using:</p>
<p>$ X_{recovered} = X_{d-proj} W_{d}^T$</p>
<p>A defining property of PCA is that for any dimension $d &lt; m$, the PCA reconstruction of the data minimizes the mean squared error between the original data among all possible $d$ dimensional hyperplanes. Moreover, the square of this error is equal to the sum of the $m-d$ smaller eigenvalues, as we shall see.</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">X_recovered</span> <span class="o">=</span> <span class="n">X2D_diy</span> <span class="o">@</span> <span class="n">W2</span><span class="o">.</span><span class="n">T</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>The squared error is then:</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">norm</span><span class="p">(</span><span class="n">X_centered</span> <span class="o">-</span> <span class="n">X_recovered</span><span class="p">)</span><span class="o">**</span><span class="mi">2</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>15.204644359438948</pre>
</div>

</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Which is equal to the sum of the two smaller eigenvalues:</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="nb">sum</span><span class="p">(</span><span class="n">eigs</span><span class="p">[</span><span class="mi">2</span><span class="p">:])</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>15.204644359438953</pre>
</div>

</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>The proportion of the total sample variance due to each sample principal component is:</p>
$$
\frac{\hat{\lambda_i}}{(\sum_{i=1}^m \hat{\lambda_i}) } \quad \quad \quad i = 1,...,m
$$<p>and is given numerically by</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">eigs</span><span class="o">/</span><span class="nb">sum</span><span class="p">(</span><span class="n">eigs</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>array([0.92461872, 0.05306648, 0.01710261, 0.00521218])</pre>
</div>

</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>We can obtain the number of principal components to retain by either (i) retaining the first $d$ components which sum up to 95% of the total variance, or (ii) looking for an elbow in the scree plot.</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>

<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="nb">len</span><span class="p">(</span><span class="n">eigs</span><span class="p">)</span><span class="o">+</span><span class="mi">1</span><span class="p">),</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">eigs</span><span class="o">.</span><span class="n">tolist</span><span class="p">()))</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="n">label</span><span class="o">=</span><span class="s2">"Scree plot"</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s2">"i"</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s2">"lambda_i"</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_png output_subarea ">
<img src="data:image/png;base64,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%0A">
</div>

</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>There is an elbow in the plot at $i = 2$, meaning all eigenvalues after $\lambda_1$ are relatively small and about the same size. In this case, it appears that the first principal component effectively summarize the total sample variance.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Finally, we can visualize the two dimensional projection using a scatter plot.</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s2">"PCA with 2 principal components"</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">14</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">X2D_diy</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">X2D_diy</span><span class="p">[:,</span><span class="mi">1</span><span class="p">],</span> <span class="n">c</span><span class="o">=</span><span class="n">iris</span><span class="p">[</span><span class="s1">'target'</span><span class="p">])</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s2">"$y_1$"</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">18</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s2">"$y_2$"</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">18</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_png output_subarea ">
<img src="data:image/png;base64,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%0A">
</div>

</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="PCA-using-scikit-learn">
<a class="anchor" href="#PCA-using-scikit-learn" aria-hidden="true"><span class="octicon octicon-link"></span></a>PCA using scikit-learn<a class="anchor-link" href="#PCA-using-scikit-learn"> </a>
</h3>
<p>Now we'll calculate the PCA projection using scikit-learn. Notice that scikit-learn will mean center the data itself.</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">pca</span> <span class="o">=</span> <span class="n">PCA</span><span class="p">(</span><span class="n">n_components</span> <span class="o">=</span> <span class="mi">2</span><span class="p">)</span>
<span class="n">X2D</span> <span class="o">=</span> <span class="n">pca</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Instead of specifing the number of components in the call to PCA above, we can also set $\operatorname{n\_components}=0.95$ to obtain the number of dimensions which capture 95% of the variance in the data. Or we could pass in no arguments to get the full SVD and plot a scree plot.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Below, we check that sklearn PCA and the one calculated with SVD directly give the same answer.</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">np</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="n">X2D</span> <span class="o">-</span> <span class="n">X2D_diy</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>2.748330173586095</pre>
</div>

</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>The non-uniquness of the PCA leads to a large difference. However, this can be fixed by inspecting the projections and adjusting:</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">X2D_diy</span><span class="p">[:,</span><span class="mi">1</span><span class="p">]</span> <span class="o">=</span> <span class="o">-</span> <span class="n">X2D_diy</span><span class="p">[:,</span><span class="mi">1</span><span class="p">]</span>
<span class="n">np</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="n">X2D</span> <span class="o">-</span> <span class="n">X2D_diy</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>1.3322676295501878e-15</pre>
</div>

</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>The explained variance ratio holds the proportion of variance explained by the first two sample principal components, and is given by</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">pca</span><span class="o">.</span><span class="n">explained_variance_ratio_</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>array([0.92461872, 0.05306648])</pre>
</div>

</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h4 id="Computational-complexity">
<a class="anchor" href="#Computational-complexity" aria-hidden="true"><span class="octicon octicon-link"></span></a>Computational complexity<a class="anchor-link" href="#Computational-complexity"> </a>
</h4>
<p>Let $n_{max} = \operatorname{max}(m,n)$ and $n_{min} = \operatorname{min}(m,n)$. If $n_{max} &lt; 500$ and $d$ is less than $80\%$ of $n_{min}$, then scikit-learn uses the full SVD approach which has a complexity of $O(n_{max}^2 n_{min})$, otherwise it uses randomized PCA which has a complexity of $O(n_{max}^2 d)$ (cf. <a href="https://scikit-learn.org/stable/modules/decomposition.html#pca-using-randomized-svd">here</a> and <a class="citation" href="#Gron2017HandsOnML">(Géron, 2017)</a>).</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>There are many more variations of PCA, and other dimensionality reduction algorithms. See <a href="https://scikit-learn.org/stable/modules/decomposition.html#decomposing-signals-in-components-matrix-factorization-problems">Decomposing signals in components (matrix factorization problems)</a> in the scikit-learn documentation, for example.</p>
<p></p>
<ol class="bibliography">
<li><span id="Johnson1982AppliedMS">Johnson, R. A., &amp; Wichern, D. W. (1982). <i>Applied Multivariate Statistical Analysis</i>.</span></li>
<li><span id="Gron2017HandsOnML">Géron, A. (2017). <i>Hands-On Machine Learning with Scikit-Learn and TensorFlow: Concepts, Tools, and Techniques to Build Intelligent Systems</i>.</span></li>
</ol>

</div>
</div>
</div>
</div>



  </div><!-- from https://github.com/utterance/utterances -->
<script src="https://utteranc.es/client.js"
        repo="krishanr/fastpages"
        issue-term="title"
        label="blogpost-comment"
        theme="github-light"
        crossorigin="anonymous"
        async>
</script><a class="u-url" href="/fastpages/statistics/2022/03/30/principal-component-analysis.html" hidden></a>
</article>

      </div>
    </main><footer class="site-footer h-card">
  <data class="u-url" href="/fastpages/"></data>

  <div class="wrapper">

    <div class="footer-col-wrapper">
      <div class="footer-col">
        <p class="feed-subscribe">
          <a href="/fastpages/feed.xml">
            <svg class="svg-icon orange">
              <use xlink:href="/fastpages/assets/minima-social-icons.svg#rss"></use>
            </svg><span>Subscribe</span>
          </a>
        </p>
      </div>
      <div class="footer-col">
        <p>My perspective on tech, math and beyond.</p>
      </div>
    </div>

    <div class="social-links"><ul class="social-media-list"><li><a rel="me" href="https://github.com/krishanr" target="_blank" title="krishanr"><svg class="svg-icon grey"><use xlink:href="/fastpages/assets/minima-social-icons.svg#github"></use></svg></a></li><li><a rel="me" href="https://twitter.com/KrishanRajarat1" target="_blank" title="KrishanRajarat1"><svg class="svg-icon grey"><use xlink:href="/fastpages/assets/minima-social-icons.svg#twitter"></use></svg></a></li></ul>
</div>

  </div>

</footer>
</body>

</html>
